{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4929255-6f23-49df-8fba-e6a0ba85d68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e99df57030d4b5bb653dc3bd0bcf815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/787k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e96c2fece9412f88c081b0a83e2ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/153 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fb503ac0b345128f016c48884706b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/259 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19137b6416764c50a68ce2252903c501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/663 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9e6d6a485e449c9aa398555816c97d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/422M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, RobertaForMaskedLM\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-roberta-base\")\n",
    "tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading\n",
    "\n",
    "model = RobertaForMaskedLM.from_pretrained(\"rinna/japanese-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d656453c-dcc8-4ef0-beac-d705f74babba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁', '子供', 'にとって', '、', 'ゲーム', 'は', '害', 'になる', 'のか', '?']\n",
      "['[CLS]', '▁', '子供', 'にとって', '、', '[MASK]', 'は', '害', 'になる', 'のか', '?']\n",
      "[4, 9, 2038, 1522, 7, 6, 11, 5596, 367, 1974, 3017]\n",
      "0 アルコール\n",
      "1 チョコレート\n",
      "2 インターネット\n",
      "3 ゲーム\n",
      "4 ストレス\n",
      "5 タバコ\n",
      "6 ギャンブル\n",
      "7 おもちゃ\n",
      "8 スポーツ\n",
      "9 いじめ\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from transformers import T5Tokenizer, RobertaForMaskedLM \n",
    "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-roberta-base\") \n",
    "tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading \n",
    "model = RobertaForMaskedLM.from_pretrained(\"rinna/japanese-roberta-base\") \n",
    "# original text \n",
    "text = \"子供にとって、ゲームは害になるのか？\"\n",
    " \n",
    "# prepend [CLS] 【注1】\n",
    "text = \"[CLS]\" + text \n",
    "# tokenize \n",
    "tokens = tokenizer.tokenize(text) \n",
    "print(tokens) \n",
    "# mask a token 【注2】\n",
    "masked_idx = 5\n",
    "tokens[masked_idx] = tokenizer.mask_token \n",
    "print(tokens) \n",
    "# convert to ids \n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens) \n",
    "print(token_ids) \n",
    "#exit() \n",
    "# convert to tensor \n",
    "token_tensor = torch.tensor([token_ids]) \n",
    "# get the top 10 predictions of the masked token \n",
    "model = model.eval() \n",
    "with torch.no_grad(): \n",
    "    outputs = model(token_tensor) \n",
    "    predictions = outputs[0][0, masked_idx].topk(10) \n",
    "for i, index_t in enumerate(predictions.indices): \n",
    "    index = index_t.item() \n",
    "    token = tokenizer.convert_ids_to_tokens([index])[0] \n",
    "    print(i, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2eb75a6d-6a75-4266-9f34-7335299a2044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "df = pd.read_csv(\"test.txt\", sep=\"\\t\", header=None, skip_blank_lines=False)\n",
    "# print(df.iloc[:,0][380:398])\n",
    "sen = \"\"\n",
    "sens = []\n",
    "for i in df.iloc[:,0]:\n",
    "    if not pd.isna(i):\n",
    "        sen += i\n",
    "    else:\n",
    "        sens.append(sen)\n",
    "        sen = \"\"\n",
    "print(len(sens))\n",
    "for sen in sens:\n",
    "    with open(\"test_orig.txt\",\"a\",encoding=\"utf8\") as f:\n",
    "        f.write(sen+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "48def458-f2bd-48fa-a0f7-3fba738a2c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3070 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8f5e4973-f5b0-4eee-ab7b-552dc6e964e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# List of all sentences in the dataset.\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "# Lists to store the current sentence.\n",
    "tokens = []\n",
    "token_labels = []\n",
    "\n",
    "# Gather the set of unique labels.\n",
    "unique_labels = set()\n",
    "\n",
    "# Read the dataset line by line. Each line of the file\n",
    "# is either empty or has two tokens, separated by a tab.\n",
    "with open(\"./dataset1/all.tsv\", newline = '') as lines:                                                                                          \n",
    "    \n",
    "    # Use the `csv` class to split the lines on the tab character.\n",
    "    line_reader = csv.reader(lines, delimiter='\\t')\n",
    "    \n",
    "    # For each line in the file...\n",
    "    for line in line_reader:\n",
    "        \n",
    "        # If we encounter a blank line, it means we've completed the previous \n",
    "        # sentence. \n",
    "        if line == []:\n",
    "\n",
    "            # Add the completed sentence.\n",
    "            sentences.append(tokens)\n",
    "            labels.append(token_labels)           \n",
    "    \n",
    "            # Start a new sentence.\n",
    "            tokens = []\n",
    "            token_labels = []        \n",
    "\n",
    "        else: \n",
    "            # Add the token and its label to the current sentence.\n",
    "            tokens.append(line[0])\n",
    "            token_labels.append(line[1])\n",
    "\n",
    "            # Add the label to the set (no effect if it already exists).\n",
    "            unique_labels.add(line[1])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "51afff69-91ce-4465-b61c-daa5b36b2adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-<t-test>', 'B-<p>', 'B-<m-val>', 'B-<m-key>', 'B-<d>', 'B-<t-key>', 'I-<timex3>', 'I-<m-val>', 'I-<c>', 'I-<p>', 'O', 'B-<c>', 'I-<r>', 'B-<timex3>', 'I-<m-key>', 'I-<t-test>', 'B-<cc>', 'B-<f>', 'I-<a>', 'I-<cc>', 'I-<t-val>', 'B-<a>', 'B-<r>', 'I-<t-key>', 'I-<f>', 'I-<d>', 'B-<t-val>'}\n"
     ]
    }
   ],
   "source": [
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "4a423d62-63a3-4be7-bb0b-fef4dfafb001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each unique label to an integer.\n",
    "label_map = {}\n",
    "\n",
    "# For each label...\n",
    "for (i, label) in enumerate(unique_labels):\n",
    "    \n",
    "    # Map it to its integer.\n",
    "    label_map[label] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6b2c509d-053c-454b-81d7-dd18a962e80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 148\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training sentences: {:,}\".format(len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f9aeb0cc-66c6-4916-bc65-5c74c360c2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence:\n",
      "    Tokens: ['【', '緒言', '】', '近年', ',', '様々', 'な', '悪性', '腫瘍', 'に', '対', 'し', 'て', '免疫', 'チェックポイント', '阻害', '薬', '(', 'ICI', ')', 'が', '適応', 'と', 'な', 'り', ',', 'その', '有効性', 'が', '認め', 'ら', 'れ', 'て', 'い', 'る', '.', '免疫', '抑制', 'シグナル', 'の', '伝達', 'を', '阻害', 'する', 'こと', 'で', '抗', '腫瘍', '効果', 'を', '示', 'す', 'が', ',', 'さまざま', 'な', '臓器', 'で', '免疫', '関連', '有害', '事象', '(', 'immune', '－', 'relate', 'd', ' ', 'adverse', ' ', 'event', 's', ' ', ':', ' ', 'irAE', ')', 'が', '報告', 'さ', 'れ', 'て', 'い', 'る', '.', '今回', ',', 'ICI', '使用', '後', 'に', '著', '明', 'な', '胆汁', 'うっ', '滞', '性', '肝', '不全', 'と', 'な', 'っ', 'た', '症例', 'を', '経験', 'し', 'た', 'ため', '報告', 'する', '.', '【', '症例', '】', '83', '歳', '男性', ',', '腎', '細胞', '癌', 'の', '胸膜', '転移', '再発', 'に', '対', 'し', 'ICI', '(', 'ニボルマブ', ',', 'イピリムマブ', '併用', ')', 'で', '加療', 'さ', 'れ', ',', '4', '回', '投与', 'さ', 'れ', 'た', 'が', '病勢', '増悪', 'あ', 'り', '中止', ',', 'その後', 'パゾパニブ', 'の', '投与', 'を', '開始', 'し', 'た', 'ところ', ',', '肝', '障害', ',', '黄疸', 'の', '出現', 'を', '認め', 'た', '.', 'パゾパニブ', '中止', 'にて', 'も', '改善', 'な', 'く', ',', ' ', 'PSL', '60', 'mg', '投与', 'を', '行われ', 'た', 'が', ',', '黄疸', 'の', '増悪', 'を', '認め', 'た', 'ため', '当', '科', '転', '院', 'と', 'な', 'っ', 'た', '.', '当', '科', '転', '院', '後', 'ステロイド', 'パルス', '療法', 'を', '行', 'っ', 'た', 'が', ',', '黄疸', 'の', '改善', 'は', '得', 'ら', 'れ', 'な', 'かった', '.', '肝', '生検', 'では', '慢性', '非', '化膿', '性', '破壊', '性', '胆', '管', '炎', ',', '著', '明', 'な', '胆汁', 'うっ', '滞', 'を', '認め', ',', 'PBC', '様', 'の', '所見', 'を', '呈', 'し', 'て', 'い', 'た', '.', '浸潤', 'する', 'リンパ球', 'は', 'CD', '8', '陽性', 'で', 'あ', 'り', 'irAE', 'によると', '考え', 'ら', 'れ', 'た', '.', 'ミコフェノール', '酸', 'モフェチル', '(', 'MMF', ')', 'を', '投与', 'し', 'た', 'が', ',', '投与', '数日後', '全身', '状態', 'の', '悪化', 'が', 'あ', 'り', '永眠', 'さ', 'れ', 'た', '.', '【', '考察', '】', '肝', '関連', 'irAE', 'は', 'ステロイド', '投与', 'が', '推奨', 'さ', 'れ', 'て', 'い', 'る', 'が', ',', '本', '症例', 'では', 'パルス', '療法', 'を', '含', 'む', 'ステロイド', '治療', 'に', '抵抗', '性', 'で', 'あ', 'っ', 'た', '.', '肝', '関連', 'irAE', 'では', '種々', 'の', 'レベル', 'の', '胆', '管', '障害', 'が', '近年', '報告', 'さ', 'れ', 'て', 'お', 'り', ',', '胆', '管', '障害', 'を', '伴', 'う', '肝', '関連', 'irAE', 'は', 'ステロイド', '抵抗', '性', 'の', '場合', 'も', '報告', 'さ', 'れ', 'て', 'い', 'る', '.', 'ステロイド', '抵抗', '性', '症例', 'では', 'MMF', 'が', '有効', 'で', 'あ', 'る', 'との', '報告', 'も', 'あ', 'り', ',', '本', '症例', 'でも', '導入', 'さ', 'れ', 'た', 'が', ',', 'その', '効果', 'を', '評価', 'する', 'こと', 'は', 'でき', 'な', 'かった', '.', '今後', ',', 'irAE', 'による', '肝', '障害', '症例', 'は', '増加', 'する', 'と', '思', 'わ', 'れ', 'る', 'が', ',', '症例', 'の', '集積', 'と', ',', '早期', 'の', '免疫', '抑制', '剤', '治療', 'を', '検討', 'する', '必要', 'が', 'あ', 'る', 'と', '思', 'わ', 'れ', 'る', '.']\n",
      "    Labels: ['O', 'O', 'O', 'B-<timex3>', 'O', 'O', 'O', 'B-<d>', 'I-<d>', 'O', 'O', 'O', 'O', 'B-<m-key>', 'I-<m-key>', 'I-<m-key>', 'I-<m-key>', 'I-<m-key>', 'I-<m-key>', 'I-<m-key>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-<a>', 'I-<a>', 'I-<a>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-<timex3>', 'O', 'B-<m-key>', 'B-<timex3>', 'I-<timex3>', 'O', 'B-<f>', 'I-<f>', 'O', 'B-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-<timex3>', 'I-<timex3>', 'O', 'O', 'B-<d>', 'I-<d>', 'I-<d>', 'O', 'B-<d>', 'I-<d>', 'I-<d>', 'O', 'O', 'O', 'B-<m-key>', 'I-<m-key>', 'I-<m-key>', 'I-<m-key>', 'I-<m-key>', 'I-<m-key>', 'I-<m-key>', 'O', 'O', 'O', 'O', 'O', 'B-<timex3>', 'I-<timex3>', 'O', 'O', 'O', 'O', 'O', 'B-<c>', 'I-<c>', 'O', 'O', 'O', 'O', 'B-<timex3>', 'B-<m-key>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'O', 'B-<c>', 'O', 'O', 'O', 'O', 'B-<m-key>', 'O', 'O', 'O', 'B-<c>', 'I-<c>', 'I-<c>', 'O', 'O', 'B-<m-key>', 'B-<m-val>', 'I-<m-val>', 'O', 'O', 'O', 'O', 'O', 'O', 'B-<d>', 'O', 'B-<c>', 'O', 'O', 'O', 'O', 'B-<cc>', 'I-<cc>', 'I-<cc>', 'I-<cc>', 'O', 'O', 'O', 'O', 'O', 'B-<timex3>', 'I-<timex3>', 'I-<timex3>', 'I-<timex3>', 'I-<timex3>', 'B-<r>', 'I-<r>', 'I-<r>', 'O', 'O', 'O', 'O', 'O', 'O', 'B-<d>', 'O', 'B-<c>', 'I-<c>', 'I-<c>', 'I-<c>', 'I-<c>', 'I-<c>', 'I-<c>', 'O', 'B-<t-test>', 'I-<t-test>', 'O', 'B-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'O', 'O', 'O', 'B-<f>', 'I-<f>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-<d>', 'I-<d>', 'I-<d>', 'O', 'B-<f>', 'I-<f>', 'I-<f>', 'O', 'O', 'O', 'B-<d>', 'O', 'O', 'O', 'O', 'O', 'O', 'B-<m-key>', 'I-<m-key>', 'I-<m-key>', 'I-<m-key>', 'I-<m-key>', 'I-<m-key>', 'O', 'O', 'O', 'O', 'O', 'O', 'B-<timex3>', 'I-<timex3>', 'B-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-<d>', 'I-<d>', 'I-<d>', 'O', 'B-<m-key>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-<r>', 'I-<r>', 'I-<r>', 'I-<r>', 'I-<r>', 'I-<r>', 'I-<r>', 'O', 'B-<f>', 'I-<f>', 'O', 'O', 'O', 'O', 'O', 'B-<d>', 'I-<d>', 'I-<d>', 'O', 'O', 'O', 'O', 'O', 'B-<d>', 'I-<d>', 'I-<d>', 'O', 'B-<timex3>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'O', 'B-<f>', 'I-<f>', 'I-<f>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-<f>', 'I-<f>', 'I-<f>', 'O', 'O', 'B-<m-key>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-<timex3>', 'O', 'B-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-<r>', 'I-<r>', 'I-<r>', 'I-<r>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Sentence Tokens and Labels:\n",
      "('【', 'O')\n",
      "('緒言', 'O')\n",
      "('】', 'O')\n",
      "('近年', 'B-<timex3>')\n",
      "(',', 'O')\n",
      "('様々', 'O')\n",
      "('な', 'O')\n",
      "('悪性', 'B-<d>')\n",
      "('腫瘍', 'I-<d>')\n",
      "('に', 'O')\n",
      "('対', 'O')\n",
      "('し', 'O')\n",
      "('て', 'O')\n",
      "('免疫', 'B-<m-key>')\n",
      "('チェックポイント', 'I-<m-key>')\n",
      "('阻害', 'I-<m-key>')\n",
      "('薬', 'I-<m-key>')\n",
      "('(', 'I-<m-key>')\n",
      "('ICI', 'I-<m-key>')\n",
      "(')', 'I-<m-key>')\n",
      "('が', 'O')\n",
      "('適応', 'O')\n",
      "('と', 'O')\n",
      "('な', 'O')\n",
      "('り', 'O')\n",
      "(',', 'O')\n",
      "('その', 'O')\n",
      "('有効性', 'O')\n",
      "('が', 'O')\n",
      "('認め', 'O')\n",
      "('ら', 'O')\n",
      "('れ', 'O')\n",
      "('て', 'O')\n",
      "('い', 'O')\n",
      "('る', 'O')\n",
      "('.', 'O')\n",
      "('免疫', 'O')\n",
      "('抑制', 'O')\n",
      "('シグナル', 'O')\n",
      "('の', 'O')\n",
      "('伝達', 'O')\n",
      "('を', 'O')\n",
      "('阻害', 'O')\n",
      "('する', 'O')\n",
      "('こと', 'O')\n",
      "('で', 'O')\n",
      "('抗', 'O')\n",
      "('腫瘍', 'O')\n",
      "('効果', 'O')\n",
      "('を', 'O')\n",
      "('示', 'O')\n",
      "('す', 'O')\n",
      "('が', 'O')\n",
      "(',', 'O')\n",
      "('さまざま', 'B-<a>')\n",
      "('な', 'I-<a>')\n",
      "('臓器', 'I-<a>')\n",
      "('で', 'O')\n",
      "('免疫', 'O')\n",
      "('関連', 'O')\n",
      "('有害', 'O')\n",
      "('事象', 'O')\n",
      "('(', 'O')\n",
      "('immune', 'O')\n",
      "('－', 'O')\n",
      "('relate', 'O')\n",
      "('d', 'O')\n",
      "(' ', 'O')\n",
      "('adverse', 'O')\n",
      "(' ', 'O')\n",
      "('event', 'O')\n",
      "('s', 'O')\n",
      "(' ', 'O')\n",
      "(':', 'O')\n",
      "(' ', 'O')\n",
      "('irAE', 'O')\n",
      "(')', 'O')\n",
      "('が', 'O')\n",
      "('報告', 'O')\n",
      "('さ', 'O')\n",
      "('れ', 'O')\n",
      "('て', 'O')\n",
      "('い', 'O')\n",
      "('る', 'O')\n",
      "('.', 'O')\n",
      "('今回', 'B-<timex3>')\n",
      "(',', 'O')\n",
      "('ICI', 'B-<m-key>')\n",
      "('使用', 'B-<timex3>')\n",
      "('後', 'I-<timex3>')\n",
      "('に', 'O')\n",
      "('著', 'B-<f>')\n",
      "('明', 'I-<f>')\n",
      "('な', 'O')\n",
      "('胆汁', 'B-<d>')\n",
      "('うっ', 'I-<d>')\n",
      "('滞', 'I-<d>')\n",
      "('性', 'I-<d>')\n",
      "('肝', 'I-<d>')\n",
      "('不全', 'I-<d>')\n",
      "('と', 'O')\n",
      "('な', 'O')\n",
      "('っ', 'O')\n",
      "('た', 'O')\n",
      "('症例', 'O')\n",
      "('を', 'O')\n",
      "('経験', 'O')\n",
      "('し', 'O')\n",
      "('た', 'O')\n",
      "('ため', 'O')\n",
      "('報告', 'O')\n",
      "('する', 'O')\n",
      "('.', 'O')\n",
      "('【', 'O')\n",
      "('症例', 'O')\n",
      "('】', 'O')\n",
      "('83', 'B-<timex3>')\n",
      "('歳', 'I-<timex3>')\n",
      "('男性', 'O')\n",
      "(',', 'O')\n",
      "('腎', 'B-<d>')\n",
      "('細胞', 'I-<d>')\n",
      "('癌', 'I-<d>')\n",
      "('の', 'O')\n",
      "('胸膜', 'B-<d>')\n",
      "('転移', 'I-<d>')\n",
      "('再発', 'I-<d>')\n",
      "('に', 'O')\n",
      "('対', 'O')\n",
      "('し', 'O')\n",
      "('ICI', 'B-<m-key>')\n",
      "('(', 'I-<m-key>')\n",
      "('ニボルマブ', 'I-<m-key>')\n",
      "(',', 'I-<m-key>')\n",
      "('イピリムマブ', 'I-<m-key>')\n",
      "('併用', 'I-<m-key>')\n",
      "(')', 'I-<m-key>')\n",
      "('で', 'O')\n",
      "('加療', 'O')\n",
      "('さ', 'O')\n",
      "('れ', 'O')\n",
      "(',', 'O')\n",
      "('4', 'B-<timex3>')\n",
      "('回', 'I-<timex3>')\n",
      "('投与', 'O')\n",
      "('さ', 'O')\n",
      "('れ', 'O')\n",
      "('た', 'O')\n",
      "('が', 'O')\n",
      "('病勢', 'B-<c>')\n",
      "('増悪', 'I-<c>')\n",
      "('あ', 'O')\n",
      "('り', 'O')\n",
      "('中止', 'O')\n",
      "(',', 'O')\n",
      "('その後', 'B-<timex3>')\n",
      "('パゾパニブ', 'B-<m-key>')\n",
      "('の', 'O')\n",
      "('投与', 'O')\n",
      "('を', 'O')\n",
      "('開始', 'O')\n",
      "('し', 'O')\n",
      "('た', 'O')\n",
      "('ところ', 'O')\n",
      "(',', 'O')\n",
      "('肝', 'B-<d>')\n",
      "('障害', 'I-<d>')\n",
      "(',', 'I-<d>')\n",
      "('黄疸', 'I-<d>')\n",
      "('の', 'O')\n",
      "('出現', 'B-<c>')\n",
      "('を', 'O')\n",
      "('認め', 'O')\n",
      "('た', 'O')\n",
      "('.', 'O')\n",
      "('パゾパニブ', 'B-<m-key>')\n",
      "('中止', 'O')\n",
      "('にて', 'O')\n",
      "('も', 'O')\n",
      "('改善', 'B-<c>')\n",
      "('な', 'I-<c>')\n",
      "('く', 'I-<c>')\n",
      "(',', 'O')\n",
      "(' ', 'O')\n",
      "('PSL', 'B-<m-key>')\n",
      "('60', 'B-<m-val>')\n",
      "('mg', 'I-<m-val>')\n",
      "('投与', 'O')\n",
      "('を', 'O')\n",
      "('行われ', 'O')\n",
      "('た', 'O')\n",
      "('が', 'O')\n",
      "(',', 'O')\n",
      "('黄疸', 'B-<d>')\n",
      "('の', 'O')\n",
      "('増悪', 'B-<c>')\n",
      "('を', 'O')\n",
      "('認め', 'O')\n",
      "('た', 'O')\n",
      "('ため', 'O')\n",
      "('当', 'B-<cc>')\n",
      "('科', 'I-<cc>')\n",
      "('転', 'I-<cc>')\n",
      "('院', 'I-<cc>')\n",
      "('と', 'O')\n",
      "('な', 'O')\n",
      "('っ', 'O')\n",
      "('た', 'O')\n",
      "('.', 'O')\n",
      "('当', 'B-<timex3>')\n",
      "('科', 'I-<timex3>')\n",
      "('転', 'I-<timex3>')\n",
      "('院', 'I-<timex3>')\n",
      "('後', 'I-<timex3>')\n",
      "('ステロイド', 'B-<r>')\n",
      "('パルス', 'I-<r>')\n",
      "('療法', 'I-<r>')\n",
      "('を', 'O')\n",
      "('行', 'O')\n",
      "('っ', 'O')\n",
      "('た', 'O')\n",
      "('が', 'O')\n",
      "(',', 'O')\n",
      "('黄疸', 'B-<d>')\n",
      "('の', 'O')\n",
      "('改善', 'B-<c>')\n",
      "('は', 'I-<c>')\n",
      "('得', 'I-<c>')\n",
      "('ら', 'I-<c>')\n",
      "('れ', 'I-<c>')\n",
      "('な', 'I-<c>')\n",
      "('かった', 'I-<c>')\n",
      "('.', 'O')\n",
      "('肝', 'B-<t-test>')\n",
      "('生検', 'I-<t-test>')\n",
      "('では', 'O')\n",
      "('慢性', 'B-<d>')\n",
      "('非', 'I-<d>')\n",
      "('化膿', 'I-<d>')\n",
      "('性', 'I-<d>')\n",
      "('破壊', 'I-<d>')\n",
      "('性', 'I-<d>')\n",
      "('胆', 'I-<d>')\n",
      "('管', 'I-<d>')\n",
      "('炎', 'I-<d>')\n",
      "(',', 'I-<d>')\n",
      "('著', 'I-<d>')\n",
      "('明', 'I-<d>')\n",
      "('な', 'I-<d>')\n",
      "('胆汁', 'I-<d>')\n",
      "('うっ', 'I-<d>')\n",
      "('滞', 'I-<d>')\n",
      "('を', 'O')\n",
      "('認め', 'O')\n",
      "(',', 'O')\n",
      "('PBC', 'B-<f>')\n",
      "('様', 'I-<f>')\n",
      "('の', 'O')\n",
      "('所見', 'O')\n",
      "('を', 'O')\n",
      "('呈', 'O')\n",
      "('し', 'O')\n",
      "('て', 'O')\n",
      "('い', 'O')\n",
      "('た', 'O')\n",
      "('.', 'O')\n",
      "('浸潤', 'B-<d>')\n",
      "('する', 'I-<d>')\n",
      "('リンパ球', 'I-<d>')\n",
      "('は', 'O')\n",
      "('CD', 'B-<f>')\n",
      "('8', 'I-<f>')\n",
      "('陽性', 'I-<f>')\n",
      "('で', 'O')\n",
      "('あ', 'O')\n",
      "('り', 'O')\n",
      "('irAE', 'B-<d>')\n",
      "('によると', 'O')\n",
      "('考え', 'O')\n",
      "('ら', 'O')\n",
      "('れ', 'O')\n",
      "('た', 'O')\n",
      "('.', 'O')\n",
      "('ミコフェノール', 'B-<m-key>')\n",
      "('酸', 'I-<m-key>')\n",
      "('モフェチル', 'I-<m-key>')\n",
      "('(', 'I-<m-key>')\n",
      "('MMF', 'I-<m-key>')\n",
      "(')', 'I-<m-key>')\n",
      "('を', 'O')\n",
      "('投与', 'O')\n",
      "('し', 'O')\n",
      "('た', 'O')\n",
      "('が', 'O')\n",
      "(',', 'O')\n",
      "('投与', 'B-<timex3>')\n",
      "('数日後', 'I-<timex3>')\n",
      "('全身', 'B-<d>')\n",
      "('状態', 'I-<d>')\n",
      "('の', 'I-<d>')\n",
      "('悪化', 'I-<d>')\n",
      "('が', 'O')\n",
      "('あ', 'O')\n",
      "('り', 'O')\n",
      "('永眠', 'O')\n",
      "('さ', 'O')\n",
      "('れ', 'O')\n",
      "('た', 'O')\n",
      "('.', 'O')\n",
      "('【', 'O')\n",
      "('考察', 'O')\n",
      "('】', 'O')\n",
      "('肝', 'B-<d>')\n",
      "('関連', 'I-<d>')\n",
      "('irAE', 'I-<d>')\n",
      "('は', 'O')\n",
      "('ステロイド', 'B-<m-key>')\n",
      "('投与', 'O')\n",
      "('が', 'O')\n",
      "('推奨', 'O')\n",
      "('さ', 'O')\n",
      "('れ', 'O')\n",
      "('て', 'O')\n",
      "('い', 'O')\n",
      "('る', 'O')\n",
      "('が', 'O')\n",
      "(',', 'O')\n",
      "('本', 'O')\n",
      "('症例', 'O')\n",
      "('では', 'O')\n",
      "('パルス', 'B-<r>')\n",
      "('療法', 'I-<r>')\n",
      "('を', 'I-<r>')\n",
      "('含', 'I-<r>')\n",
      "('む', 'I-<r>')\n",
      "('ステロイド', 'I-<r>')\n",
      "('治療', 'I-<r>')\n",
      "('に', 'O')\n",
      "('抵抗', 'B-<f>')\n",
      "('性', 'I-<f>')\n",
      "('で', 'O')\n",
      "('あ', 'O')\n",
      "('っ', 'O')\n",
      "('た', 'O')\n",
      "('.', 'O')\n",
      "('肝', 'B-<d>')\n",
      "('関連', 'I-<d>')\n",
      "('irAE', 'I-<d>')\n",
      "('では', 'O')\n",
      "('種々', 'O')\n",
      "('の', 'O')\n",
      "('レベル', 'O')\n",
      "('の', 'O')\n",
      "('胆', 'B-<d>')\n",
      "('管', 'I-<d>')\n",
      "('障害', 'I-<d>')\n",
      "('が', 'O')\n",
      "('近年', 'B-<timex3>')\n",
      "('報告', 'O')\n",
      "('さ', 'O')\n",
      "('れ', 'O')\n",
      "('て', 'O')\n",
      "('お', 'O')\n",
      "('り', 'O')\n",
      "(',', 'O')\n",
      "('胆', 'B-<d>')\n",
      "('管', 'I-<d>')\n",
      "('障害', 'I-<d>')\n",
      "('を', 'I-<d>')\n",
      "('伴', 'I-<d>')\n",
      "('う', 'I-<d>')\n",
      "('肝', 'I-<d>')\n",
      "('関連', 'I-<d>')\n",
      "('irAE', 'I-<d>')\n",
      "('は', 'O')\n",
      "('ステロイド', 'B-<f>')\n",
      "('抵抗', 'I-<f>')\n",
      "('性', 'I-<f>')\n",
      "('の', 'O')\n",
      "('場合', 'O')\n",
      "('も', 'O')\n",
      "('報告', 'O')\n",
      "('さ', 'O')\n",
      "('れ', 'O')\n",
      "('て', 'O')\n",
      "('い', 'O')\n",
      "('る', 'O')\n",
      "('.', 'O')\n",
      "('ステロイド', 'B-<f>')\n",
      "('抵抗', 'I-<f>')\n",
      "('性', 'I-<f>')\n",
      "('症例', 'O')\n",
      "('では', 'O')\n",
      "('MMF', 'B-<m-key>')\n",
      "('が', 'O')\n",
      "('有効', 'O')\n",
      "('で', 'O')\n",
      "('あ', 'O')\n",
      "('る', 'O')\n",
      "('との', 'O')\n",
      "('報告', 'O')\n",
      "('も', 'O')\n",
      "('あ', 'O')\n",
      "('り', 'O')\n",
      "(',', 'O')\n",
      "('本', 'O')\n",
      "('症例', 'O')\n",
      "('でも', 'O')\n",
      "('導入', 'O')\n",
      "('さ', 'O')\n",
      "('れ', 'O')\n",
      "('た', 'O')\n",
      "('が', 'O')\n",
      "(',', 'O')\n",
      "('その', 'O')\n",
      "('効果', 'O')\n",
      "('を', 'O')\n",
      "('評価', 'O')\n",
      "('する', 'O')\n",
      "('こと', 'O')\n",
      "('は', 'O')\n",
      "('でき', 'O')\n",
      "('な', 'O')\n",
      "('かった', 'O')\n",
      "('.', 'O')\n",
      "('今後', 'B-<timex3>')\n",
      "(',', 'O')\n",
      "('irAE', 'B-<d>')\n",
      "('による', 'I-<d>')\n",
      "('肝', 'I-<d>')\n",
      "('障害', 'I-<d>')\n",
      "('症例', 'O')\n",
      "('は', 'O')\n",
      "('増加', 'O')\n",
      "('する', 'O')\n",
      "('と', 'O')\n",
      "('思', 'O')\n",
      "('わ', 'O')\n",
      "('れ', 'O')\n",
      "('る', 'O')\n",
      "('が', 'O')\n",
      "(',', 'O')\n",
      "('症例', 'O')\n",
      "('の', 'O')\n",
      "('集積', 'O')\n",
      "('と', 'O')\n",
      "(',', 'O')\n",
      "('早期', 'O')\n",
      "('の', 'O')\n",
      "('免疫', 'B-<r>')\n",
      "('抑制', 'I-<r>')\n",
      "('剤', 'I-<r>')\n",
      "('治療', 'I-<r>')\n",
      "('を', 'O')\n",
      "('検討', 'O')\n",
      "('する', 'O')\n",
      "('必要', 'O')\n",
      "('が', 'O')\n",
      "('あ', 'O')\n",
      "('る', 'O')\n",
      "('と', 'O')\n",
      "('思', 'O')\n",
      "('わ', 'O')\n",
      "('れ', 'O')\n",
      "('る', 'O')\n",
      "('.', 'O')\n"
     ]
    }
   ],
   "source": [
    "print(\"Example sentence:\")\n",
    "print (\"    Tokens:\", sentences[4])\n",
    "print (\"    Labels:\", labels[4])\n",
    "\n",
    "print ('\\nSentence Tokens and Labels:')\n",
    "for i in zip(sentences[4], labels[4]):\n",
    "  print (i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e9cf1a64-3cde-4397-96f8-9888a56f03b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring sentence lengths...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, RobertaForTokenClassification, AdamW, RobertaConfig\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-roberta-base\")\n",
    "tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading\n",
    "\n",
    "# Record the length of each sequence.\n",
    "lengths = []\n",
    "\n",
    "print('Measuring sentence lengths...')\n",
    "\n",
    "# For every sentence...\n",
    "for sen in sentences:\n",
    "\n",
    "    # Reconstruct the sentence to let BERT decide how to tokenize it.\n",
    "    sen = ' '.join(sen)\n",
    "\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sen,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Record the length of the sentence after tokenization.\n",
    "    lengths.append(len(encoded_sent))\n",
    "\n",
    "print('    DONE.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6308bc24-d804-4de6-a296-16041cfcdd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Min length: 212 tokens\n",
      "   Max length: 1,482 tokens\n",
      "Median length: 701 tokens\n"
     ]
    }
   ],
   "source": [
    "print('   Min length: {:,} tokens'.format(min(lengths)))\n",
    "print('   Max length: {:,} tokens'.format(max(lengths)))\n",
    "print('Median length: {:,} tokens'.format(int(np.median(lengths))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "24b6ba5c-596c-46b2-a1f1-de9af74f09e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '# of Sentences')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnAAAAFjCAYAAAC9uTYLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABLeUlEQVR4nO3dfVzN9/8/8MfpkhRdrETkas4ppQs0MmPSUJ+lzHXKzFauRzaTmc+Mz2dsCyOZaRh+lqsihlzLXI9GmsY0UeiClJN0/f790bfzcZxTTnXqOHrcb7fdbs7r/Trv9/P96uz06H3xeosEQRBARERERFpDR9MFEBEREVHNMMARERERaRkGOCIiIiItwwBHREREpGUY4IiIiIi0DAMcERERkZZhgCMioloJDAyEh4eHpssgapQY4IhIJi0tDfPnz8fgwYPh7OwMNzc3eHl5Yc6cOTh37lyD1HD+/HmEh4fj8ePHDbK9hpaeng6JRIKFCxdquhSVxMTE4Oeff9Z0GUT0HD1NF0BEL4erV68iMDAQenp68PPzw+uvv47CwkLcvn0bp0+fRrNmzdCrV696r+PChQtYtWoVhg4diubNm9f79qh6u3btwt27dzF+/HhNl0JEz2CAIyIAQEREBJ4+fYrY2FjY2dkpLM/OztZAVUREpAxPoRIRACA1NRWmpqZKwxsAWFpaKrSdOXMGEyZMQI8ePdC1a1f4+PggKipKoZ+HhwcCAwORkpKC4OBguLq6onv37vj444/lgmFoaChWrVoFABgwYAAkEgkkEgnCw8NlfaRSKb777ju88847cHR0RK9evTBr1iykpaXJbTMmJgYSiQRnz57FunXr4OnpCUdHRwwaNAi7du1Suo/nzp1DcHAwevbsia5du2LAgAH4/PPPkZOTI9dv//79GDNmDFxdXeHs7IwRI0YgLi6uipGtvaysLHz55Zd4++234ejoiD59+mD+/Pl4+PChXL/w8HBIJBL8888/WLZsGfr27QtHR0cMGTIE8fHxCut9+vQpFi9ejD59+sDJyQkjR47E2bNnERoaColEIuvn4eGBCxcu4O7du7KfhUQiwfnz5+XWl5mZiVmzZsHNzQ3Ozs748MMPcevWLbk+RUVFCA8Px6BBg+Ds7IwePXrAx8cH33zzjRpHjKjx4BE4IgIA2Nra4tatWzh06BAGDhz4wv7btm3Dl19+CRcXF0yaNAlNmzbFmTNnsGDBAty5cwdz5syR65+ZmYlx48bB09MTn332Gf766y9s27YN+fn5WL9+PQBg1KhRyM/Px+HDhzF37lyYmZkBgCxUSKVSjB49Gvfu3cOwYcPQuXNnZGdn45dffsGIESMQHR0NGxsbue0uX74chYWFGDVqFAwMDBAVFYXQ0FDY2tqie/fusn5bt27FggUL0LJlS4wePRo2Nja4d+8ejh8/jszMTJibm8vWt2bNGrz11luYMWMGdHR0cPjwYcyYMQP//ve/MXbs2Nr/EJ5x7949jBo1CiUlJRg+fDhsbW1x+/ZtREVF4fz584iOjoaJiYnce0JDQ6Gnp4cJEyagpKQEGzduxNSpUxEXF4c2bdrI+s2YMQPx8fHw9PRE7969kZ6ejqlTp8r1AYDPP/8cS5cuxaNHjzB37lxZe6dOnWT/LigoQEBAAJydnRESEoL09HRs2rQJU6ZMwa+//gpdXV0AwFdffYXo6Gj4+fnB1dUVZWVlSE1NVQiDRKQigYhIEISEhATBwcFBEIvFwsCBA4XQ0FBhy5Ytws2bNxX6ZmZmCo6OjsKsWbMUli1atEiws7MT7ty5I2vr37+/IBaLhX379sn1XbBggSAWi4WUlBRZ28qVKwWxWCykpaUpXXfXrl2F5ORkufb09HTB1dVVmDNnjqwtOjpaEIvFgq+vr1BUVCRrz8jIEBwcHISQkBBZ2/379wUHBwfBy8tLyMvLU9huWVmZIAiCkJSUJIjFYmHp0qUKfSZPniy4uroKUqlUYdmz0tLSBLFYLHz11VfV9ps0aZLQq1cv4f79+3LtiYmJgr29vbBy5UpZW+WYBQcHC+Xl5bL2K1euCGKxWAgLC5O1nThxQhCLxcK8efPk1lvZLhaL5doDAgKE/v37K60xICBAEIvFwtq1a+XaIyMjBbFYLJw8eVLW5ubmJnz00UfV7jMRqY6nUIkIAODq6oro6GgMHToUUqkUMTEx+Oqrr+Dt7Y2xY8fKnaI8ePAgiouLMXz4cOTk5Mj95+HhgfLycpw5c0Zu/VZWVvD29pZrq7wp4vbt2y+sTxAE7N27F25ubrCyspLbZtOmTeHi4oJTp04pvM/f3x8GBgay1y1btkSHDh2Qmpoqa4uLi0NJSQmmTZum9MYJHZ2Kr8q9e/dCJBLBz89P6X4/efIEly9ffuG+vIhUKsWJEyfg4eEBAwMDue3Y2NjA1tYWp0+fVnjfuHHjIBKJZK+dnJxgZGQkN77Hjh0DAHzwwQdy7+3Xr5/ckTVV6ejoYNy4cXJtyn6uxsbGuHnzJm7cuFHjbRCRIp5CJSIZiUSCJUuWAADu3r2L33//HTt27MDFixcxZcoUREdHw8DAACkpKQBQ7Z2JDx48kHvdtm1bhT6mpqYAgNzc3BfWlpOTg9zcXJw6dQru7u5K+1QGLVW2e/fuXdnryjBnb29fbQ0pKSkQBAFeXl5V9nl+v2vj1q1bKC8vx86dO7Fz506lfZTtl7I2MzMzPHr0SPY6PT0dOjo6sLW1VejboUMH2c9WVVZWVjA0NJRrU/Zz/fzzz/HZZ5/Bx8cHbdu2Rc+ePdG/f394eHgo/bkRUfUY4IhIKRsbG9jY2MDX1xf+/v5ISEhAYmIievToAUEQAADffPMNrKyslL7/+TBReS2UMpXrq05ln969eyMoKEjV3VBrOBAEASKRCJGRkVXuz+uvv66W7QDAkCFDMHToUKV9ng9NQM329dkjdXWh6s/V09MTx44dQ3x8PH7//XecOXMGO3fuRI8ePbBhwwa5o6RE9GIMcERULZFIBGdnZyQkJCArKwsA0L59ewAVR3d69+6t9u0pY25ujubNmyM/P1/t26zcn+TkZHTo0KHafr/99htat25dq9ONqrK1tYVIJEJJSYna99XGxgbl5eW4ffu2wj48f+eoupmamsLX1xe+vr4QBAFhYWH46aefcPTo0WqPahKRIh63JiIAwOnTp1FaWqrQXlhYKLveqvIXvpeXFwwMDBAeHo7CwkKF90ilUhQXF9eqDiMjIwBAXl6eXLuOjg58fHyQmJhY5ZQdz0+voarBgwdDX18fERERyM/PV1j+7BExAFi2bBnKysoU+qnj9ClQEYz79euHw4cPK72mThAEhalNVFX56Kvnn64QHx+v9PRps2bNkJeXp9JR0qqUlZUpPFlDJBKhS5cuABR/1kT0YjwCR0QAgMWLFyM3NxceHh4Qi8Vo0qQJMjIysHfvXqSmpsLPz082nYe1tTUWLFiAL774At7e3hgyZAhsbGyQk5ODGzdu4MiRI9i3b5/CtBSqcHZ2BgCEhYXBx8cHhoaG6Ny5M8RiMUJCQpCQkICZM2fCy8sLzs7O0NfXx71793Dy5Ek4ODjIruGrCWtra3z++edYuHAhfHx84OvrCxsbG2RmZuLo0aP4+uuvYW9vDycnJ0yfPh3h4eHw8/PDoEGD0LJlS2RlZeHPP//EyZMnkZSUpNI2k5KSsHr1aoV2PT09BAcHY8GCBfD390dAQAB8fX3RpUsXlJeXIy0tDUePHoWfnx+mT59e433t168f+vTpg+3bt+PRo0dwd3dHeno6tm/fDolEguvXr8v1d3Z2xvHjx7Fw4UK4urpCV1cXvXr1goWFhcrbfPLkCfr06QMPDw906dIF5ubmSE9PR1RUFFq0aIH+/fvXeD+IGjsGOCICUDGH2NGjR3Hp0iUcPHgQUqkUJiYmEIvFCAoKwnvvvSfXf9iwYWjfvj3Wr1+Pbdu2QSqVwtTUFB06dMCMGTOUTvyriu7du+PTTz/F1q1bMX/+fJSWlmLatGkQi8UwMTFBVFQU1q9fj7i4OBw9ehS6urqwtrZG9+7dMWLEiFrvv7+/P2xtbbFu3Tps3rwZxcXFsLKygru7O6ytrWX9pk2bBkdHR2zevBmbNm1CQUEBLCws0LlzZ8ybN0/l7V25cgVXrlxRaDcwMEBwcDBatWqF6OhoREZG4tixY9izZw8MDQ3RqlUr9O/fv9anHEUiEcLDw7F8+XLs27cPJ0+ehEQiwapVqxAVFaVwR/D48eORlpaGgwcPYuvWrSgvL8emTZtqFOCaNGmC999/H2fPnsXZs2fx5MkTWFlZwcPDAxMnTkTLli1rtS9EjZlIqMtxcSIiemX4+PigpKSkXp4qQUTqxWvgiIgaGWXXLZ44cQI3btzAm2++qYGKiKimeAqViKiRiYiIwLVr19CzZ0+YmJggOTkZMTExMDU1rdEULUSkOTyFSkTUyMTHx2Pt2rW4efMm8vPz0aJFC/Tq1QszZsxAu3btNF0eEamAAY6IiIhIy/AaOCIiIiItwwBHREREpGUa5U0Mjx49QXm5es4cW1gY4+FDxZnbSTUcv7rh+NUNx69uOH51w/Grm8Ywfjo6IpiZNVO6rFEGuPJyQW0BrnJ9VHscv7rh+NUNx69uOH51w/Grm8Y8fjyFSkRERKRlGOCIiIiItAwDHBEREZGWYYAjIiIi0jIMcERERERahgGOiIiISMswwBERERFpGQY4IiIiIi3DAEdERESkZRrlkxiISDuUlgNFJaX1tn4hpwAFRepZv6G+HvT4JzERNRAGOCJ6aRWVlOL35Mx6W7+JcRNI8wvVsi43+5bQM+RXKhE1DP69SERERKRlNPbn4tWrV7FmzRpcu3YNDx8+hImJCezs7DB16lR069ZNrm9CQgK+++47XLt2DcbGxvDy8sInn3yCpk2baqh6IiIiIs3RWIBLS0tDWVkZRowYAUtLS0ilUuzduxcBAQGIjIzEm2++CQBITk7G+PHj8frrryM0NBQZGRlYv3490tPTsWbNGk2VT0RERKQxGgtw3t7e8Pb2lmsbM2YMPD09sWnTJlmAW7ZsGUxNTbF582Y0a9YMANCmTRt88cUXOHv2LNzd3Ru8diIiIiJNeqmugWvatCnMzc3x+PFjAEB+fj7OnDkDPz8/WXgDAF9fXxgZGeHAgQOaKpWIiIhIYzR+y1R+fj6Ki4uRm5uL3bt348aNG5g6dSoA4Pr16ygtLYWjo6PcewwMDGBvb4/k5GRNlExERESkURoPcJ9//jkOHjwIANDX18fo0aMxadIkAEB2djYAwNLSUuF9lpaWuHz5coPVSURERPSy0HiAmzp1KkaNGoWMjAzExsaiuLgYJSUlMDAwQGFhxfxMBgYGCu8zNDSULa8pCwvjOtX8PEtLE7Wur7Hh+NXNqzx+Qk4BTIyb1Os21LV+IyNDWJobqWVd2uRV/vw1BI5f3TTm8dN4gJNIJJBIJACAIUOGYNiwYZg7dy5WrlyJJk0qvliLi4sV3ldUVCRbXlMPH+ajvFyofdHPsLQ0QXa2VC3raow4fnXzqo9fQVGp2ibaVUadE/kWFBQhu6xMLevSFq/656++cfzqpjGMn46OqMqDTi/VTQz6+voYMGAADh06hMLCQtmp08pTqc/Kzs6GlZVVQ5dIREREpHEvVYADgMLCQgiCgCdPnkAsFkNPTw9JSUlyfYqLi5GcnAx7e3sNVUlERESkORoLcDk5OQpt+fn5OHjwIFq1agULCwuYmJjA3d0dsbGxePLkiaxfbGwsCgoKMHjw4IYsmYiIiOiloLFr4GbOnAlDQ0O4urrC0tIS9+/fR0xMDDIyMrBs2TJZv5CQEIwePRqBgYEYMWIEMjIysGHDBvTt2xe9e/fWVPlEREREGqOxADdkyBDExsZi8+bNePz4MUxMTODi4oJvv/0Wb7zxhqyfg4MDNmzYgLCwMCxevBjGxsYYOXIkZs2apanSiYiIiDRKYwFu+PDhGD58uEp9e/Toga1bt9ZzRURERETa4aW7iYGIiIiIqscAR0RERKRlGOCIiIiItAwDHBEREZGWYYAjIiIi0jIMcERERERahgGOiIiISMswwBERERFpGY1N5Ev0KiotB4pKShtse0JOAQqKar49Q3096PHPNyIircUAR6RGRSWl+D05s8G2Z2LcBNL8whq/z82+JfQM+b8/EZG24t/gRERERFqGAY6IiIhIyzDAEREREWkZBjgiIiIiLcMAR0RERKRlGOCIiIiItAwDHBEREZGWYYAjIiIi0jIMcERERERahgGOiIiISMswwBERERFpGQY4IiIiIi3DAEdERESkZRjgiIiIiLQMAxwRERGRlmGAIyIiItIyDHBEREREWoYBjoiIiEjL6Glqw4mJidi1axfOnz+Pe/fuwdTUFK6urpg5cybatWsn6xcYGIgLFy4ovN/b2xvLly9vyJKJiIiIXgoaC3A//fQTEhISMHjwYEgkEmRnZ2PLli3w8/PDzp070alTJ1nf1q1bY+bMmXLvt7GxaeCKiYiIiF4OGgtw48ePR1hYGAwMDGRt3t7e8PHxQWRkJJYsWSJrb968OXx9fTVRJhEREdFLR2PXwHXr1k0uvAFA+/bt0blzZ6SkpCj0Ly0txZMnTxqqPCIiIqKX1kt1E4MgCHjw4AHMzMzk2lNSUuDi4oJu3bqhT58+WLNmDcrLyzVUJREREZFmaewUqjJ79uxBZmYmQkJCZG1t27ZFz549IZFIkJ+fj19//RXLly/HvXv3sHDhQg1WS0RERKQZIkEQBE0XAVQcZRs5ciQkEgn+3//7f9DRqfrg4IwZM3Dw4EHs378fHTt2bMAqiaqXlVOAhOtZmi7jhbpJrGBlbqTpMl5IW8YT0J4xJaJXw0txBC47OxsTJ05EixYtsGLFimrDGwBMmDABcXFxOH/+fK0C3MOH+SgvV09utbQ0QXa2VC3raoxetfErKCqFNL+wwbZnYtykVtsrKChCdllZPVSkXvU9nrUdP2W0ZUzV6VX7/7ehcfzqpjGMn46OCBYWxkqXaTzASaVSBAUFQSqVIioqCpaWli98j7W1NQAgLy+vvssjIiIieuloNMAVFRVh0qRJSE1Nxc8//6zy0bS0tDQAgLm5eX2WR0RERPRS0thdqGVlZZg5cyYuX76MFStWwMXFRaFPfn4+iouLFd73448/QkdHB+7u7g1ULREREdHLQ2NH4JYsWYJjx46hf//+yM3NRWxsrGxZs2bN4OnpiT///BOffPIJ3n33Xdja2qKgoAAHDhxAUlISgoKC0LZtW02VT0RERKQxKge4R48eIScnR+4RV2lpafj555+Rm5sLPz8/vPXWWypv+K+//gIAHD9+HMePH5dbZmNjA09PT7Ru3RrdunXDoUOH8ODBA+jo6KBz585YsmQJhg4dqvK2iIiIiF4lKge4//73v0hNTcXOnTsBAE+ePMHYsWORlVVxi/+BAwewceNGuLm5qbS+zZs3v7BP27ZtsXLlSlVLJCIiImoUVA5wly9flnse6f79+5GVlYW1a9fC3t4eEyZMwE8//aRygCOqidJyoKikVNNlvJCaZqchIiKqlsoB7uHDh7LpOwDgt99+g6OjI/r27QsAGDp0KDZs2KD+ColQEd5+T87UdBkv5Cx+8TQ4REREdaXyXah6enooKiqSvb5w4YLc0TYTExPk5uaqtTgiIiIiUqRygGvfvj0OHjwIQRBw9OhR5OXlyU3jkZGRgRYtWtRLkURERET0PyqfQh07dixCQ0Ph5uaGwsJCtG3bVi7AXbx4ERKJpF6KJCIiIqL/UTnA+fn5AQCOHj0KY2NjTJo0Cfr6+gAqphiRSqUYM2ZMvRRJRERERP9To4l8/fz8ZEHuWWZmZoiJiVFXTURERERUjVo9Suv27du4dOkSpFKpuushIiIioheoUYA7fvw4PD09MXjwYAQEBCApKQlAxRQj77zzDuLi4uqlSCIiIiL6H5UD3Pnz5zFt2jS0aNECU6dOhSD8b8ZSCwsL2NraYv/+/fVSJBERERH9j8oBLiIiAhKJBDt27MDYsWMVlru4uODPP/9Ua3FEREREpEjlAHf16lUMGTIEOjrK32JtbY0HDx6orTAiIiIiUk7lACcIgmzaEGUePXpU7XIiIiIiUg+VA1zHjh1x6dKlKpcfP34cdnZ2aimKiIiIiKqmcoAbPnw4Dh48iB07dshuYBCJRHj69Cn+85//4PLlyxg5cmS9FUpEREREFVSeyNff3x8JCQmYP38+vvnmG4hEInzyySfIzc1FWVkZ3nvvPQwZMqQ+ayUiIiIi1PBJDGFhYRg0aBD27NmDf/75B4IgwMnJCX5+fhg0aFB91UhEREREz6hRgAOAd955B++880591EJEREREKlD5GrjS0lLk5+dXuTw/Px+lpaVqKYqIiIiIqqZygFuyZAmGDRtW5fJhw4YhLCxMLUURERERUdVUDnCnTp3CwIEDq1w+aNAgnDx5Ui1FEREREVHVVA5wGRkZsLW1rXJ527Ztcf/+fbUURURERERVUznA6evrIysrq8rl2dnZVT5mi4iIiIjUR+XEZWdnh7i4OBQXFyssKykpwYEDByCRSNRaHBEREREpUjnABQQE4O+//8bEiRNx9epVFBcXo6SkBFevXsXEiRNx8+ZNBAQE1GetRERERIQazAM3aNAgTJw4ET/++CNGjhwJkUgEkUiE8vJyCIKAoKAgeHt712etRERERIQaTuQbEhKCAQMGYM+ePbhz5w4AoH379nj33Xfh5ORULwUSERERkbwaP4nBycmJYY2IiIhIg2oc4NQlMTERu3btwvnz53Hv3j2YmprC1dUVM2fORLt27eT6JiQk4LvvvsO1a9dgbGwMLy8vfPLJJ2jatKmGqiciIiLSnBoFuHv37mHbtm1ITU1Fbm4uBEGQWy4SibBx40aV1vXTTz8hISEBgwcPhkQiQXZ2NrZs2QI/Pz/s3LkTnTp1AgAkJydj/PjxeP311xEaGoqMjAysX78e6enpWLNmTU3KJyIiInolqBzg4uPjMW3aNJSUlMDIyAimpqZ12vD48eMRFhYGAwMDWZu3tzd8fHwQGRmJJUuWAACWLVsGU1NTbN68Gc2aNQMAtGnTBl988QXOnj0Ld3f3OtVBREREpG1UDnDLli2DmZkZIiIi0LVr1zpvuFu3bgpt7du3R+fOnZGSkgIAyM/Px5kzZ/Dhhx/KwhsA+Pr64uuvv8aBAwcY4IiIiKjRUXkeuH/++Qfvv/++WsJbVQRBwIMHD2BmZgYAuH79OkpLS+Ho6CjXz8DAAPb29khOTq63WoiIiIheViofgTM3N4e+vn591oI9e/YgMzMTISEhACoezwUAlpaWCn0tLS1x+fLlWm3HwsK41jUqY2lpotb1NTaqjJ+QUwAT4yYNUE3d6OvrNXidtdmegaE+BN2X/9F3uvq127+aUNf6jYwMYWlupJZ1aRN+/9UNx69uGvP4qRzgfH19cejQIYwbN65eCklJScHChQvRvXt3+Pr6AgAKCwsBQO46uUqGhoay5TX18GE+ysuFF3dUgaWlCbKzpWpZV2Ok6vgVFJVCml+7n3dDKilp2DpNjJvUanv5BUW4ciO7HipSL2exZb2OZ23HT5mCgiJkl5WpZV3agt9/dcPxq5vGMH46OqIqDzqpHOCGDh2K8+fPY/LkyRg3bhzatGkDXV1dhX6tW7eucYHZ2dmYOHEiWrRogRUrVkBHp+LIQJMmFX8ZK3v+alFRkWw5ERERUWOicoDz8vKCSCSCIAg4ceJElf1qel2aVCpFUFAQpFIpoqKi5E6XVv678lTqs7Kzs2FlZVWjbRERERG9ClQOcFOnToVIJFLrxouKijBp0iSkpqbi559/RseOHeWWi8Vi6OnpISkpCQMHDpS1FxcXIzk5GT4+Pmqth4iIiEgbqBzgpk+frtYNl5WVYebMmbh8+TJWr14NFxcXhT4mJiZwd3dHbGwsJk6cKJtKJDY2FgUFBRg8eLBaayIiIiLSBhp7lNaSJUtw7Ngx9O/fH7m5uYiNjZUta9asGTw9PQEAISEhGD16NAIDAzFixAhkZGRgw4YN6Nu3L3r37q2p8omIiIg0pkYBLj8/Hz///DNOnz6Nhw8f4ptvvoGrqytycnLwyy+/wMvLS/YIrBf566+/AADHjx/H8ePH5ZbZ2NjIApyDgwM2bNiAsLAwLF68GMbGxhg5ciRmzZpVk9KJiIiIXhkqB7icnByMGTMG6enpsLW1RVpammwaD3Nzc+zevRtSqRRz585VaX2bN29WucgePXpg69atKvcnIiIiepWpHOC+//57PHjwANu3b0erVq0UTl8OGDAAZ8+eVXuBRERERCRP5anYjx8/Dn9/fzg4OCi9G7Vt27bIyMhQa3FEREREpEjlAPfo0SPY2tpWuVwkEqGoqEgtRRERERFR1VQOcJaWlkhLS6tyeXJyMlq1aqWWooiIiIioaioHuL59+2Lnzp3IyspSWHblyhXs3r0bAwYMUGtxRERERKRI5ZsYpk2bhmPHjmHo0KHw8PCASCTC7t27sWPHDhw6dAhWVlYICgqqz1qJiIiICDU8hbp9+3Y4OTkhOjoagiAgNjYWBw4cQJ8+ffDLL7/A1NS0HkslIiIiIqCGE/m2atUKP/zwA/Lz8/HPP/8AAGxtbRnciIiIiBqQykfgdu/ejfT0dACAsbExnJyc4OTkJAtv6enp2L17d33USERERETPUDnAzZ07F3/88UeVyxMTE1V+CgMRERER1Z7KAU4QhGqXl5SUQEdH5dURERERUS3VKHEpewIDADx+/Bjx8fGwtLRUS1FEREREVLVqb2JYtWoVIiIiAFSEt9mzZ2P27NlV9v/ggw/UWx0RERERKag2wNnZ2cHPzw+CIGD37t3o0aMH2rZtq9CvWbNmcHZ2xrvvvltvhRIRERFRhWoDnKenJzw9PQEAd+/exZQpU+Du7t4ghRERERGRcirPA7d58+b6rIOIiIiIVFSjiXwB4OnTp7h79y5yc3OV3pnq5uamlsKIiIiISDmVA1xBQQGWLFmCmJgYlJWVKSwXBAEikQjJyclqLZCIiIiI5Kkc4L7++mvs3LkT/fr1Q69evfj4LCIiIiINUTnAHT58GP/617+wdOnS+qyHiIiIiF5A5Yl8i4uL0bNnz/qshYiIiIhUoHKAc3R0RGpqaj2WQkRERESqUDnAffLJJ4iJicHVq1frsx4iIiIiegGVr4Hbtm0brK2tMWrUKLi4uKBt27YKD68XiUT4+uuv1V4kEREREf2PygFu165dsn8nJCQgISFBoQ8DHBEREVH9UznA/fXXX/VZBxERERGpSOVr4IiIiIjo5VDjR2kVFBTg8uXLePDgAXr37o3XXnutPuoiIiIioirUKMD98ssvWLZsGfLz8yESibB+/Xq89tprePjwId5++23Mnz8fI0eOVHl9WVlZ2LRpE65cuYKkpCQUFBRg06ZNCvPNeXh44O7duwrvDwoKwqefflqTXSAiIiLSeioHuIMHD2LhwoUYMGAA+vfvjy+++EK2zMLCAm+99RaOHDlSowB369YtREZGol27dpBIJPjjjz+q7Ovg4ID3339frk0sFqu8LSIiIqJXhcoBbt26dejZsyciIiLw6NEjuQAHVEz0u2PHjhpt3MHBAefOnYOZmRmOHDmCqVOnVtnX2toavr6+NVo/ERER0atI5ZsYbty4gXfeeafK5ZaWlnj48GGNNm5sbAwzMzOV+xcXF+Pp06c12gYRERHRq0blAKejo4Py8vIql2dlZaFp06ZqKUqZ06dPw8XFBS4uLvD09MS2bdvqbVtERERELzOVT6Ha2dnh1KlTGDdunMKy8vJyxMXFoWvXrmotrpJYLEaPHj3Qvn17PHr0CNu3b8e///1v5OXlITg4uMbrs7AwVmt9lpYmal1fY6PK+Ak5BTAxbtIA1dSNvr5eg9dZm+1pos7aaIg61bV+IyNDWJobqWVd2oTff3XD8aubxjx+Kge4gIAAzJo1C99//z38/PwAAIIg4J9//sHy5ctx8+bNersjdM2aNXKv33vvPfj7+2P16tUYM2YMTExq9gN8+DAf5eWCWmqztDRBdrZULetqjFQdv4KiUkjzCxugoropKWnYOk2Mm9Rqew1dZ23Vd521HT9lCgqKkF1WppZ1aQt+/9UNx69uGsP46eiIqjzopHKA8/b2xvXr17FmzRqsXbsWAPDRRx9BEAQIgoBp06ahX79+6qn4BXR1dfH+++8jJCQEf/zxB/r27dsg2yUiIiJ6GdRoHriQkBAMHDgQe/fuxT///ANBENCuXTv4+vrW2+nTqlhbWwMA8vLyGnS7RERERJpW4ycxODg4wMHBoT5qqZG0tDQAgLm5uYYrISIiImpYdXoWamZmJhITE/H48WN11aMgNzdX4e7XoqIirFu3Ds2aNYOLi0u9bZuIiIjoZVTtEbjk5GScO3cOfn5+cvO15eTk4LPPPsPp06cBVFyTNmnSJEybNq3GBaxevRoAkJKSAgCIjY3FpUuX0Lx5cwQEBODYsWNYs2YNBg0aBBsbG+Tm5mLXrl1ITU3FggUL0KxZsxpvk4iIiEibVRvgoqKicPLkSXzwwQdy7V988QVOnTqFtm3bwt7eHpcuXUJERATs7Ozg6elZowJWrFgh9zo6OhoAYGNjg4CAAIjFYnTs2BGxsbHIycmBgYEBHBwcEBoaiv79+9doW0RERESvgmoD3OXLlxXu8Lx79y6OHTsGOzs7bN++HQYGBsjJycF7772H7du31zjAXb9+vdrljo6OCtOIEBERETVm1V4Dl5WVhfbt28u1nTt3DgDg7+8PAwMDABU3EgwZMgTXrl2rnyqJiIiISKbaAFdQUKAwSW5iYiJEIhF69uwp1962bVvk5uaqvUAiIiIikldtgLO2tsadO3fk2v744w80b94c7dq1k2svKyvjDQVEREREDaDaAOfo6Ijdu3cjKysLQEV4u3HjBtzd3RX63rx5E1ZWVvVTJRERERHJVHsTQ3BwMA4ePAgvLy906NABN2/ehI6OjtIH2p84cULhtCoRERERqV+1R+Ds7OywatUqtG7dGjdu3ECbNm2wfPlydOvWTa7fb7/9hocPH/KZpEREREQN4IWP0urfv/8L51t766238Mcff6itKCIiIiKqWp0epUVEREREDY8BjoiIiEjLMMARERERaRkGOCIiIiItwwBHREREpGWqDHCrVq3CjRs3ZK/v3buHwsLCBimKiIiIiKpWbYC7fv267PWAAQNw+PDhBimKiIiIiKpWZYBr3rw5Hj9+LHstCEKDFERERERE1atyIl97e3usW7cOpaWlaNGiBQDg4sWLKCsrq3aFfn5+ai2QiIiIiORVGeDmzp2LadOmYfHixQAAkUiEbdu2Ydu2bVWuTCQSMcARERER1bMqA5ydnR0OHjyItLQ0ZGdnIzAwEJMmTULv3r0bsj4iIiIiek61z0LV1dVF+/bt0b59e7i5uaFnz5544403Gqo2IiIiIlLihQ+zr7R58+b6rIOIiIiIVKRygAOA8vJy7Nq1C4cPH0Z6ejoAoE2bNhg4cCD8/Pygo8N5gYmIiIjqm8oBrrCwEEFBQbh48SJEIhEsLS0BACdPnkR8fDx2796NyMhIGBoa1luxRERERFSDR2n98MMP+P333/HBBx/g7NmziI+PR3x8PM6dO4cJEybgwoUL+OGHH+qzViIiIiJCDQLc/v374eXlhc8++0w2LxxQMeHv7Nmz4eXlhX379tVLkURERET0PyoHuIyMjGrvQHVzc0NGRoZaiiIiIiKiqqkc4Jo3b447d+5UufzOnTto3ry5WooiIiIioqqpHOB69+6NLVu24LffflNYdurUKURFRaFPnz5qLY6IiIiIFKl8F+rMmTNx6tQpBAcHw97eHp07dwYA/P3330hOToaZmRk+/vjjGm08KysLmzZtwpUrV5CUlISCggJs2rQJPXv2VOh79OhRrFq1Cjdv3oSFhQWGDx+OSZMmQU+vRjOhEBEREWk9lY/A2djYIDo6Gt7e3khNTUVsbCxiY2Nx+/Zt/Otf/8LOnTthY2NTo43funULkZGRyMzMhEQiqbJffHw8pk6dihYtWmD+/Pnw9PRERESE7DmtRERERI1JjQ5ftW7dGkuXLoUgCMjJyQEAmJubQyQS1WrjDg4OOHfuHMzMzHDkyBFMnTpVab9vv/0WXbp0wbp166CrqwsAaNasGdauXYvAwEC0b9++VtsnIiIi0ka1enSCSCSChYUFLCwsah3eAMDY2BhmZmbV9rl58yZu3ryJUaNGycIbAPj7+6O8vByHDh2q9faJiIiItNFL/+yra9euAQAcHR3l2lu2bAlra2vZciIiIqLG4qUPcNnZ2QAge3TXsywtLZGVldXQJRERERFp1Et/C2dhYSEAwMDAQGGZoaEhnj59WuN1WlgY17muZ1lamqh1fY2NKuMn5BTAxLhJA1RTN/r6eg1eZ222p4k6a6Mh6lTX+o2MDGFpbqSWdWkTfv/VDcevbhrz+L30Aa5Jk4ov1+LiYoVlRUVFsuU18fBhPsrLhTrXBlR8eLKzpWpZV2Ok6vgVFJVCml/YABXVTUlJw9ZpYtykVttr6Dprq77rrO34KVNQUITssjK1rEtb8Puvbjh+ddMYxk9HR1TlQaeX/hRq5anTylOpz8rOzoaVlVVDl0RERESkUS99gLO3twcAJCUlybVnZmYiIyNDtpyIiIiosVA5wOXn52PcuHENftdn586d0bFjR2zbtg1lz5yeiIqKgo6ODgYOHNig9RARERFpmsrXwJWUlODChQvIy8sDABQUFGDRokX46KOP0KlTp1oXsHr1agBASkoKACA2NhaXLl1C8+bNERAQAAD47LPPMHnyZHz44Yfw9vbGjRs3sGXLFowaNQodOnSo9baJiIiItFG1Ae7jjz9Gt27d4OrqCmtra7llRUVF2L17N4YMGVKnALdixQq519HR0QAqHt1VGeD69++PVatWYdWqVVi0aBHMzc0xefJkTJkypdbbJSIiItJW1Qa4p0+fIiIiAlKpFHp6ehCJRDhw4ACMjIzQpk0bCELd7+S8fv26Sv08PT3h6elZ5+0RERERabtqA1xkZCQEQcD169dx+vRpfPfdd9i7dy+2b98OIyMjiEQinDhxAi1atIC9vX2dHqtFRERERKp54U0MIpEIdnZ2eO+99wBUXLMWGxuLoKAgCIKALVu2YNiwYXjjjTcwceLEei+YiIiIqLGr9gjchx9+iO7du6N79+5o27YtgIpAJ5FIYGlpiRUrVuDHH39E8+bN8fvvv+PixYsNUjQRERFRY1ZtgDMwMMDmzZuxcuVK6OrqQiQSYdeuXQCAjh07AgB0dXXRtWtXdO3aFRMmTKj/iomIiIgauWoD3A8//AAASE1NxenTp7Fo0SIcP34csbGxMDQ0hEgkwqFDh9CkSRM4OjpCT++lfzIXERERkdZTaSLf9u3bw9vbG0DFtB8HDhzA1KlTIQgCdu3ahdGjR8PNzQ3jx4+vz1qJiIiICLV8lFaHDh0wYsQIABU3Nezbtw+zZ8+Gubm5WosjIiIiIkUqn/M0NDTE0KFDlT48vlOnTujUqRP8/f3VWhwRERERKVI5wBkZGWHx4sWy19UFOiKixkakI8KTolJNl/FChvp60KvVuRciepnU+q6D5wMdEVFjVlRShis3sjVdxgu52beEniFvOCPSdvw7jIiIiEjLMMARERERaRkGOCIiIiItwwBHREREpGUY4IiIiIi0DAMcERERkZZhgCMiIiLSMpwMiIioEVHnhMNCTgEK6mnyYk44TFQ9BjgiokZEnRMOmxg3gTS/UC3reh4nHCaqHv++ISIiItIyDHBEREREWoYBjoiIiEjLMMARERERaRkGOCIiIiItwwBHREREpGV4j3YjVloOFJXUzxxOqlJ1HqlyoQGKISKqhdp+l9bnPHrKcG69VwsDXCNWVFKK35MzNVqDqvNIOYstG6AaIqKaq+13aX3Oo6cM59Z7tTCLExEREWkZrYji58+fx7hx45Qu279/Pzp16tTAFRERERFpjlYEuErvv/8+HBwc5NpatmypoWqIiIiINEOrAtwbb7wBT09PTZdBREREpFFadw1cfn4+Sks1e+ckERERkSZp1RG42bNno6CgAHp6eujZsyfmzJkDiUSi6bKIiIiIGpRWBDh9fX0MGjQIffv2hZmZGa5fv47169fD398fO3fuRIcOHTRdIhEREVGD0YoA161bN3Tr1k32esCAAfDw8MCwYcOwatUqLF26tEbrs7AwVmt9lpYmal1fQxFyCmBi3ETTZahUg76+3ktR64toos7abI/j+T/qWn9jHdP62mcDQ30IutpxlY+ufu3HoSE/M9oypjo6QHn5i/tl5RQAurr1X1AVmjbRg4mRgca2rxUBThk7Ozu4u7vj3LlzNX7vw4f5KFfT1P6WlibIzpaqZV0NraCotEEnkVRG1YksS0o0X6sqGrrO2k4EyvGsoM6JVBvjmNbnRLT5BUW4ciO7Xtatbs5iy1qNQ0NP5KstY+ostlSpzoYev+e52bdE4ZOiet2Gjo6oyoNOL38Ur0arVq2Ql5en6TKIiIiIGpRWB7i0tDSYmZlpugwiIiKiBqUVAS4nJ0eh7eLFizh//jz69OmjgYqIiIiINEcrroGbOXMmmjZtCldXV5iZmeHvv//Gtm3bYGZmhunTp2u6PCIiIqIGpRUBztPTE3v37sWGDRuQn58Pc3NzvPvuu5g+fTpat26t6fKIiIiIGpRWBLhx48ZV+TB7IiIiosZGK66BIyIiIqL/YYAjIiIi0jIMcERERERahgGOiIiISMswwBERERFpGQY4IiIiIi3DAEdERESkZRjgiIiIiLSMVkzkq21Ky4GiklJNl/FC5YKmKyAiIqLaYICrB0Ulpfg9OVPTZbyQs9hS0yUQERFRLfAUKhEREZGWYYAjIiIi0jIMcERERERahgGOiIiISMswwBERERFpGQY4IiIiIi3DAEdERESkZRjgiIiIiLQMAxwRERGRlmGAIyIiItIyDHBEREREWoYBjoiIiEjLMMARERERaRkGOCIiIiItwwBHREREpGUY4IiIiIi0DAMcERERkZZhgCMiIiLSMloT4IqLi/Hdd9+hT58+cHJywsiRI3H27FlNl0VERETU4LQmwIWGhmLjxo0YMmQI5s2bBx0dHQQFBeGPP/7QdGlEREREDUorAlxiYiL27duHTz/9FJ999hlGjRqFjRs3olWrVggLC9N0eUREREQNSisCXFxcHPT19TFixAhZm6GhIYYPH45Lly4hKytLg9URERERNSw9TRegiuTkZHTo0AHNmjWTa3dycoIgCEhOToaVlZXK69PREam1vufXp6erA6Mm+mrdRn14GepsaqiHstIX1/Ay1KqKhq5T1fF7HsezQm3HT5nGOKbqHL/nact4ArWvtT7HTxltGVNV62zo8Xuenq6O2vPE86pbv1YEuOzsbLRs2VKh3dLSEgBqfATOzKzZizvVgIWFsUJbm1Yt1LqN+tKxjZmmS1CZttTKOtVLW+oEtKdW1ql+2lIr63x1aMUp1MLCQujrK6ZsQ0NDAEBRUVFDl0RERESkMVoR4Jo0aYKSkhKF9srgVhnkiIiIiBoDrQhwlpaWSk+TZmdnA0CNrn8jIiIi0nZaEeDs7Oxw69YtPHnyRK79ypUrsuVEREREjYVWBLjBgwejpKQEO3bskLUVFxcjJiYG3bp1U3qDAxEREdGrSivuQnV2dsbgwYMRFhaG7Oxs2NraYteuXbh37x4WL16s6fKIiIiIGpRIEARB00WooqioCN9//z327t2LvLw8SCQSzJo1C71799Z0aUREREQNSmsCHBERERFV0Ipr4IiIiIjofxjgiIiIiLQMA9z/SUxMxFdffQVvb2+4uLjg7bffRkhICG7fvq3QNyEhAWPGjIGzszPefPNN/Oc//8HTp08V+hUXF+O7775Dnz594OTkhJEjR+Ls2bMNsTsaFxkZCYlEAl9fX4VlHD/lEhMTERwcDDc3N7i6umLIkCGIiYmR63P06FEMHToUXbt2xdtvv41Vq1ahtLRUYV2PHz/G/Pnz0atXL7i4uGDcuHFITk5uqF1pcKmpqZg5cyb69u0LFxcXeHt7Y+3atSguLpbrx89exaMHw8LCEBgYCFdXV0gkEpw/f15p3/r4vKm6zpeVKuP36NEj/PTTT/D390evXr3Qo0cPjBo1CgcOHFC6zsYyfjX57FW6e/cunJ2dIZFIlI5JYxk7ZRjg/s9PP/2Ew4cPo3fv3pg3bx5GjhyJCxcuwM/PDykpKbJ+ycnJGD9+PIqKihAaGorhw4dj27ZtCAkJUVhnaGgoNm7ciCFDhmDevHnQ0dFBUFAQ/vjjj4bctQaXnZ2NH374AUZGRgrLOH7KxcfHw9/fH6WlpZgxYwbmzJmD3r174/79+3J9pk6dihYtWmD+/Pnw9PRERESEwp3Y5eXlCA4Oxr59+xAQEIDZs2fj4cOHCAwMxJ07dxp61+pdZmYmRowYgcTERAQEBGDu3LlwcHDA0qVLMW/ePFk/fvYq3Lp1C5GRkcjMzIREIqmyX3183lRd58tMlfG7fPkyvv/+e5iammLy5MkICQmBoaEhZs6ciYiICLm+jWn8VP3sPeubb76Bjo7yqNKYxk4pgQRBEIRLly4JRUVFcm23bt0SHB0dhTlz5sjaPvroI+Gtt94S8vPzZW3bt28XxGKxcObMGVnblStXBLFYLGzYsEHWVlhYKHh6egr+/v71tyMvgTlz5giBgYFCQECAMGTIELllHD9Fjx8/Ftzd3YVFixZV28/b21sYOnSoUFpaKmtbtmyZYGdnJ9y6dUvWtm/fPkEsFguHDx+WtT18+FDo0aOHMHv2bLXXr2k//vijIBaLhRs3bsi1T58+XejSpYtQXFwsCAI/e5WkUqmQk5MjCIIgHD58WBCLxcK5c+cU+tXH503Vdb7MVBm/O3fuCOnp6XJt5eXlwrhx4wQnJyfh6dOnsvbGNH6qfvYqnTt3TnBwcBCWLVsmiMVi4dq1a3LLG9PYKcMjcP+nW7duMDAwkGtr3749OnfuLDsCl5+fjzNnzsDPzw/NmjWT9fP19YWRkZHc4fG4uDjo6+tjxIgRsjZDQ0MMHz4cly5dUvposFdBYmIi9uzZg7lz5yos4/gpt3fvXjx+/BgzZswAUDFOwnM3h9+8eRM3b97EqFGjoKurK2v39/dHeXk5Dh06JGs7ePAgrKysMGDAAFmbubk5vLy8cOTIEaXPFdZmlU9osbCwkGt/7bXXoKenB11dXX72nmFsbAwzM7Nq+9TH560m63yZqTJ+bdu2hY2NjVybSCSCp6cnCgsLcffuXVl7Yxo/VcauUllZGf773/8iICAA7dq1U9qnMY2dMgxw1RAEAQ8ePJB94K5fv47S0lI4OjrK9TMwMIC9vb3ceffk5GR06NBB7pcFADg5OUEQhFfyeiRBELBo0SL4+fnB3t5eYTnHT7mzZ8+iY8eOiI+PR79+/dC9e3e88cYbCAsLQ1lZGQDg2rVrAKAwdi1btoS1tbVsOVAxdg4ODhCJRHJ9u3btiidPnrxyp1Hd3NwAAPPmzcNff/2F+/fvY8+ePdi1axeCgoKgo6PDz14N1cfnrSbrfFU9ePAAAORCDMdPua1btyIzMxNTpkypsk9jHzsGuGrs2bMHmZmZ8PLyAlBxbRcAWFpaKvS1tLSU+8s8OzsbVlZWSvsB0Pq/4pXZvXs3bt68iZkzZypdzvFT7vbt28jIyEBoaCiGDh2K8PBweHp6IjIyEkuWLAGgnrGrbHuVxg4A+vTpgxkzZuDMmTPw9fXF22+/jdmzZ+Ojjz7CtGnTAPCzV1P18XmryTpfRbm5udixYwfeeOMNmJuby9o5fopyc3OxcuVKTJ8+Hc2bN6+yX2MfO614lJYmpKSkYOHChejevbvsTsrCwkIAUDjVClScYqlcXtlXX19faT+g4skSr5L8/HwsXboUwcHBSv+HAjh+VSkoKEBeXh4++eQTBAcHAwAGDhyIgoICREVFYfLkyS8cu2fvpCwsLFTar7Lt2XF+VbRp0wZvvPEG3nnnHZiamuLEiRMIDw+Hubk5xowZw89eDdXH560m63zVlJeX49NPP4VUKsUXX3wht4zjp2jlypUwNzfH6NGjq+3X2MeOAU6J7OxsTJw4ES1atMCKFStkd8A0adIEABSmJgAqvtQrl1f2VXatUeWXf+Uvg1fFDz/8AH19fXzwwQdV9uH4KVe53++++65cu4+PD+Li4nD16tUaj52yfpVtz/Z9Fezbtw9ffvkl4uLi0LJlSwAVAVgQBHz77bfw9vbmZ6+G6uPzVpN1vmoWLVqEU6dOISwsTOHuS46fvBs3bmDr1q344YcfoKdXfURp7GPHU6jPkUqlCAoKglQqxU8//SR3yLXy35WHY5/1/KHcqg7LVr63qqNU2igrKwsbN26Ev78/Hjx4gPT0dKSnp6OoqAglJSVIT09HXl4ex68KlePy2muvybVXvlbX2FW2vUpjBwC//PILHBwcZOGtkoeHBwoKCvDXX3/xs1dD9fF5q8k6XyWrVq3CL7/8gtmzZyv8kQZw/J63bNkydOnSBZ06dZL9Lnn06BGAijF5dmqlxj52DHDPKCoqwqRJk5Camooff/wRHTt2lFsuFouhp6eHpKQkufbi4mIkJyfLXbhvZ2eHW7duye6Qq3TlyhXZ8lfFw4cPUVJSgrCwMAwYMED235UrV5CSkoIBAwYgMjKS41cFBwcHABXzmT0rIyMDQMVdVZVj8/zYZWZmIiMjQ2Hs/vzzT4U7WRMTE2FkZARbW1u174MmPXjwQHazx7Mqj6KVlZXxs1dD9fF5q8k6XxVbtmxBeHg4xo8fjw8//FBpH46fvPv37+Pq1atyv0u+/fZbAEBwcDCGDx8u69vYx44B7v+UlZVh5syZuHz5MlasWAEXFxeFPiYmJnB3d0dsbKzcl3tsbCwKCgowePBgWdvgwYNRUlKCHTt2yNqKi4sRExODbt26KRwt0GZt2rRBRESEwn+dO3eGjY0NIiIi4Ofnx/GrQuV+79y5U9YmCAJ27NgBIyMjuLi4oHPnzujYsSO2bdsmF1aioqKgo6ODgQMHyq0vKysLR48elbXl5OQgLi4OAwYMUHp9lzbr0KEDkpKSFO6u3bdvH3R1dSGRSPjZq6H6+LzVZJ2vgv379+M///kPfHx8EBoaWmU/jp+8uXPnKvwuCQwMlC17duLdxj52IuH56NpI/fe//8WmTZvQv39/2V2nlZo1awZPT08AwJ9//onRo0ejc+fOGDFiBDIyMrBhwwb07NkTkZGRcu+bMWMGjh49ivfffx+2trbYtWsXkpKSsHHjRnTv3r3B9k1TAgMD8fjxY8TGxsraOH7KzZkzB7GxsRg+fDi6dOmC+Ph4nDhxQnY3JQAcP34ckydPRq9eveDt7Y0bN25gy5YtGDVqFBYsWCBbV1lZGfz9/fH3339jwoQJMDMzQ1RUFO7fv4+YmJgq51TSVr///jvef/99mJmZYezYsWjRogVOnDiBkydPYvTo0fjqq68A8LP3rNWrVwOouFnr119/xbBhw9CmTRs0b94cAQEBAOrn86bqOl92Lxq/xMRE+Pv7w8TEBJ9++qnCtVxvvvmm7BKJxjZ+qnz2nhcTE4O5c+di9+7dckfLGtvYPY8B7v8EBgbiwoULSpfZ2Njg2LFjstcXL15EWFgYrl27BmNjY3h7e2PWrFkKj44qKirC999/j7179yIvLw8SiQSzZs1C796963VfXhbKAhzA8VOmuLgYq1evxu7du/HgwQO0adMG48ePV7gL68iRI1i1ahVSUlJgbm6OYcOGYcqUKQq/IPLy8vDtt9/iyJEjKCoqQteuXREaGio7XfuqSUxMRHh4OJKTk5GbmwsbGxsMGzYMH374odzEnfzsVajqMUbPf9fVx+dN1XW+zF40fpWBoyqbNm1Cz549Za8b0/ip+tl7VlUBDmhcY/c8BjgiIiIiLcNr4IiIiIi0DAMcERERkZZhgCMiIiLSMgxwRERERFqGAY6IiIhIyzDAEREREWkZBjgiIiIiLcMAR0REahMYGAgPDw9Nl0H0ymOAI6JqpaWlYf78+Rg8eDCcnZ3h5uYGLy8vzJkzB+fOnWuQGs6fP4/w8HA8fvy4QbbX0NLT0yGRSLBw4UJNl6KSmJgY/Pzzz5oug6hR087nRxBRg7h69SoCAwOhp6cHPz8/vP766ygsLMTt27dx+vRpNGvWDL169ar3Oi5cuIBVq1Zh6NChaN68eb1vj6q3a9cu3L17F+PHj9d0KUSNFgMcEVUpIiICT58+RWxsLOzs7BSWZ2dna6AqIiLiKVQiqlJqaipMTU2VhjcAsLS0VGg7c+YMJkyYgB49eqBr167w8fFBVFSUQj8PDw8EBgYiJSUFwcHBcHV1Rffu3fHxxx/LBcPQ0FCsWrUKADBgwABIJBJIJBKEh4fL+kilUnz33Xd455134OjoiF69emHWrFlIS0uT22ZMTAwkEgnOnj2LdevWwdPTE46Ojhg0aBB27dqldB/PnTuH4OBg9OzZE127dsWAAQPw+eefIycnR67f/v37MWbMGLi6usLZ2RkjRoxAXFxcFSNbe1lZWfjyyy/x9ttvw9HREX369MH8+fPx8OFDuX7h4eGQSCT4559/sGzZMvTt2xeOjo4YMmQI4uPjFdb79OlTLF68GH369IGTkxNGjhyJs2fPIjQ0VO4B5B4eHrhw4QLu3r0r+1lIJBKcP39ebn2ZmZmYNWsW3Nzc4OzsjA8//BC3bt1S+3gQNVY8AkdEVbK1tcWtW7dw6NAhDBw48IX9t23bhi+//BIuLi6YNGkSmjZtijNnzmDBggW4c+cO5syZI9c/MzMT48aNg6enJz777DP89ddf2LZtG/Lz87F+/XoAwKhRo5Cfn4/Dhw9j7ty5MDMzAwBZqJBKpRg9ejTu3buHYcOGoXPnzsjOzsYvv/yCESNGIDo6GjY2NnLbXb58OQoLCzFq1CgYGBggKioKoaGhsLW1Rffu3WX9tm7digULFqBly5YYPXo0bGxscO/ePRw/fhyZmZkwNzeXrW/NmjV46623MGPGDOjo6ODw4cOYMWMG/v3vf2Ps2LG1/yE84969exg1ahRKSkowfPhw2Nra4vbt24iKisL58+cRHR0NExMTufeEhoZCT08PEyZMQElJCTZu3IipU6ciLi4Obdq0kfWbMWMG4uPj4enpid69eyM9PR1Tp06V6wMAn3/+OZYuXYpHjx5h7ty5svZOnTrJ/l1QUICAgAA4OzsjJCQE6enp2LRpE6ZMmYJff/0Vurq6ahkPokZNICKqQkJCguDg4CCIxWJh4MCBQmhoqLBlyxbh5s2bCn0zMzMFR0dHYdasWQrLFi1aJNjZ2Ql37tyRtfXv318Qi8XCvn375PouWLBAEIvFQkpKiqxt5cqVglgsFtLS0pSuu2vXrkJycrJce3p6uuDq6irMmTNH1hYdHS2IxWLB19dXKCoqkrVnZGQIDg4OQkhIiKzt/v37goODg+Dl5SXk5eUpbLesrEwQBEFISkoSxGKxsHTpUoU+kydPFlxdXQWpVKqw7FlpaWmCWCwWvvrqq2r7TZo0SejVq5dw//59ufbExETB3t5eWLlypaytcsyCg4OF8vJyWfuVK1cEsVgshIWFydpOnDghiMViYd68eXLrrWwXi8Vy7QEBAUL//v2V1hgQECCIxWJh7dq1cu2RkZGCWCwWTp48We0+EpFqeAqViKrk6uqK6OhoDB06FFKpFDExMfjqq6/g7e2NsWPHyp2iPHjwIIqLizF8+HDk5OTI/efh4YHy8nKcOXNGbv1WVlbw9vaWa6u8KeL27dsvrE8QBOzduxdubm6wsrKS22bTpk3h4uKCU6dOKbzP398fBgYGstctW7ZEhw4dkJqaKmuLi4tDSUkJpk2bpvTGCR2diq/PvXv3QiQSwc/PT+l+P3nyBJcvX37hvryIVCrFiRMn4OHhAQMDA7nt2NjYwNbWFqdPn1Z437hx4yASiWSvnZycYGRkJDe+x44dAwB88MEHcu/t16+f3JE1Veno6GDcuHFybTX5uRLRi/EUKhFVSyKRYMmSJQCAu3fv4vfff8eOHTtw8eJFTJkyBdHR0TAwMEBKSgoAVHtn4oMHD+Ret23bVqGPqakpACA3N/eFteXk5CA3NxenTp2Cu7u70j6VQUuV7d69e1f2ujLM2dvbV1tDSkoKBEGAl5dXlX2e3+/auHXrFsrLy7Fz507s3LlTaR9l+6WszczMDI8ePZK9Tk9Ph46ODmxtbRX6dujQQfazVZWVlRUMDQ3l2mrycyWiF2OAIyKV2djYwMbGBr6+vvD390dCQgISExPRo0cPCIIAAPjmm29gZWWl9P3Ph4nqroWqXF91Kvv07t0bQUFBqu6G0lBXW4IgQCQSITIyssr9ef3119WyHQAYMmQIhg4dqrTP86EJqNm+Pnukri7q+nMlohdjgCOiGhOJRHB2dkZCQgKysrIAAO3btwdQcXSnd+/eat+eMubm5mjevDny8/PVvs3K/UlOTkaHDh2q7ffbb7+hdevWtTrdqCpbW1uIRCKUlJSofV9tbGxQXl6O27dvK+wD7xwlejnxGjgiqtLp06dRWlqq0F5YWCi73qryF76XlxcMDAwQHh6OwsJChfdIpVIUFxfXqg4jIyMAQF5enly7jo4OfHx8kJiYWOWUHc9Pr6GqwYMHQ19fHxEREcjPz1dY/uwRMQBYtmwZysrKFPqp4/QpUBGM+/Xrh8OHDyu9pk4QBIWpTVRV+eir55+uEB8fr/T0abNmzZCXl8ejaUQaxCNwRFSlxYsXIzc3Fx4eHhCLxWjSpAkyMjKwd+9epKamws/PTzadh7W1NRYsWIAvvvgC3t7eGDJkCGxsbJCTk4MbN27gyJEj2Ldvn8K0FKpwdnYGAISFhcHHxweGhobo3LkzxGIxQkJCkJCQgJkzZ8LLywvOzs7Q19fHvXv3cPLkSTg4OMiu4asJa2trfP7551i4cCF8fHzg6+sLGxsbZGZm4ujRo/j6669hb28PJycnTJ8+HeHh4fDz88OgQYPQsmVLZGVl4c8//8TJkyeRlJSk0jaTkpKwevVqhXY9PT0EBwdjwYIF8Pf3R0BAAHx9fdGlSxeUl5cjLS0NR48ehZ+fH6ZPn17jfe3Xrx/69OmD7du349GjR3B3d0d6ejq2b98OiUSC69evy/V3dnbG8ePHsXDhQri6ukJXVxe9evWChYVFjbdNRLXDAEdEVQoNDcXRo0dx6dIlHDx4EFKpFCYmJhCLxQgKCsJ7770n13/YsGFo37491q9fj23btkEqlcLU1BQdOnTAjBkzlE78q4ru3bvj008/xdatWzF//nyUlpZi2rRpEIvFMDExQVRUFNavX4+4uDgcPXoUurq6sLa2Rvfu3TFixIha77+/vz9sbW2xbt06bN68GcXFxbCysoK7uzusra1l/aZNmwZHR0ds3rwZmzZtQkFBASwsLNC5c2fMmzdP5e1duXIFV65cUWg3MDBAcHAwWrVqhejoaERGRuLYsWPYs2cPDA0N0apVK/Tv37/aGymqIxKJEB4ejuXLl2Pfvn04efIkJBIJVq1ahaioKIU7R8ePH4+0tDQcPHgQW7duRXl5OTZt2sQAR9SARAKPgRMRURV8fHxQUlJSL0+VIKLa4zVwRESk9LrFEydO4MaNG3jzzTc1UBERVYenUImICBEREbh27Rp69uwJExMTJCcnIyYmBqampjWaooWIGgZPoRIREeLj47F27VrcvHkT+fn5aNGiBXr16oUZM2agXbt2mi6PiJ7DAEdERESkZXgNHBEREZGWYYAjIiIi0jIMcERERERahgGOiIiISMswwBERERFpGQY4IiIiIi3z/wHe1H9jD6IMEQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "\n",
    "# Plot the distribution of comment lengths.\n",
    "sns.distplot(lengths, kde=False, rug=False)\n",
    "\n",
    "plt.title('Sentence Lengths')\n",
    "plt.xlabel('Sentence Length')\n",
    "plt.ylabel('# of Sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a49ccce4-14d9-46b6-bffb-92707db01f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  ['症例', 'は', '70', '歳', ',', '男性', '.', '血', '疾', 'を', '主訴', 'に', '当院', '紹介', 'と', 'な', 'り', ',', 'CT', '・', '気管支', '鏡', '検査', 'の', '結果', ',', '非', '小', '細胞', '肺癌', 'と', '診断', 'さ', 'れ', 'た', '.', 'その後', ',', '放射線', '化学療法', '(', '１', ' ', '+', ' ', 'CDDP', '療法', ')', 'が', '導入', 'さ', 'れ', ',', '2', 'コース', '施行', '後', 'の', '維持', '療法', 'として', 'デュルバルマブ', '療法', '(', '抗', 'PD', '－', 'L', '1', '抗体', '療法', ')', 'を', '行', 'っ', 'た', 'ところ', ',', '発熱', 'と', '炎症', '反応', '上昇', 'を', '認め', 'た', 'ため', '抗', 'PD', '－', 'L', '1', '抗体', '投与', '5日', '後', 'から', 'LVFX', '投与', 'を', '開始', 'し', 'た', '.', 'LVFX', '投与', '3口', '目', 'の', '採血', 'で', '肝', '機能障害', 'と', '炎症', '反応', 'の', '更なる', '上昇', 'を', '認め', 'た', 'ため', '造影', 'CT', 'を', '施行', 'し', 'た', 'ところ', ',', '肺癌', 'に', '対', 'する', '放射線', '治療', 'の', '照射', '範囲', 'に', '含まれ', 'る', '肝臓', '領域', 'に', '多発', 'する', '造影', '効果', 'が', '乏し', 'い', '小', '腫瘤', 'を', '認め', 'た', '.', '経過', 'から', '多発', '肝', '膿瘍', 'または', '肺癌', 'の', '多発', '肝', '転移', 'を', '疑', 'い', ',', '肝', '腫瘍', '生検', 'を', '施行', 'し', 'た', 'ところ', ',', '病理', '組織', '所見', 'は', '凝固', '壊死', 'と', '思', 'わ', 'れ', 'る', '肝細胞', '壊死', 'を', '散見', 'し', ',', '明らか', 'な', '肺癌', 'の', '肝', '浸潤', '所見', 'は', '認め', 'ら', 'れ', 'な', 'かった', '.', '血液', '培養', 'も', '施行', 'し', 'た', 'が', '菌', 'は', '検出', 'さ', 'れ', 'な', 'かった', '.', '以上', 'の', '結果', 'から', '炎症', 'による', '多発', '肝', '腫瘤', 'と', '判断', 'し', ',', '抗生', '剤', '投与', 'を', '継続', 'し', 'た', 'ところ', '抗生', '剤', '投与', '開始', 'から', '1', '週間', '後', 'には', '炎症', '反応', 'の', '改善', 'を', '認め', 'た', '.', 'しかし', ',', '同時期', 'に', '施行', 'し', 'た', 'EOB', '－', 'MRI', 'では', '多発', '肝', '腫瘤', 'は', '残存', 'し', 'て', 'い', 'た', '.', '2', 'ヶ月', '後', 'に', '施行', 'し', 'た', 'CT', 'では', '肝', '腫瘤', 'の', '減少', 'を', '認め', ',', '3', 'ヶ月', '後', 'の', 'CT', 'では', 'ほぼ', '肝', '腫瘤', 'は', '消失', 'し', 'て', 'い', 'た', '.', '考察', ':', '非', '小', '細胞', '肺癌', 'に', '対', 'する', '放射線', '化学療法', '施行', '後', 'の', '抗', 'PD', '－', 'L', '1', '抗体', '投与', 'が', '影響', 'し', 'た', 'と', '思', 'わ', 'れ', 'る', '壊死', '性', '多発', '肝', '腫瘤', 'の', '1', '例', 'を', '経験', 'し', 'た', '.', '近年', ',', '抗', 'PD', '－', 'L', '1', '抗体', 'を', '含め', 'た', '免疫', 'チェックポイント', '阻害', '薬', 'は', '様々', 'な', '癌', '種', 'に', '使用', 'さ', 'れ', 'る', 'よう', 'に', 'な', 'っ', 'て', 'い', 'る', 'が', ',', '使用', '経験', 'は', '浅', 'く', ',', 'その', '副作用', 'に', '関', 'し', 'て', 'も', '十分', '判明', 'し', 'て', 'い', 'ない', '.', '本', '症例', 'の', '病理', '組織', 'は', '免疫', 'チェックポイント', '阻害', '薬', 'による', '自己', '免疫', '的', 'な', '機', '序', 'より', 'は', '放射線', '化学療法', 'による', '肝', '障害', 'を', '疑', 'う', '所見', 'で', 'あ', 'っ', 'た', 'が', ',', '放射線', '化学療法', 'のみ', 'で', '照射', '範囲', 'の', '肝臓', 'に', '壊死', '性', 'の', '多発', '肝', '腫瘤', 'が', '出現', 'する', 'こと', 'は', '極めて', '稀', 'で', 'あ', 'る', '.', 'この', 'ため', '本', '症例', 'では', '放射線', '化学療法', 'に', '加え', ',', '抗', 'PD', '－', 'L', '1', '抗体', 'を', '投与', 'し', 'た', 'こと', 'が', '壊死', '性', '多発', '肝', '腫瘤', '発生', 'に', '影響', 'を', '及ぼ', 'し', 'た', '可能性', 'が', '高', 'い', 'と', '考え', 'た', '.', '結語', ':', '非', '小', '細胞', '肺癌', 'に', '対', 'する', '放射線', '化学療法', '施行', '後', 'の', '抗', 'PD', '－', 'Ll', '抗体', '投与', 'が', '影響', 'し', 'た', 'と', '思', 'わ', 'れ', 'る', '壊死', '性', '多発', '肝', '腫瘤', 'の', '1', '例', 'を', '経験', 'し', 'た', '.', 'これまで', '同様', 'の', '報告', 'は', '存在', 'せ', 'ず', '興味深', 'い', '症例', 'と', '思', 'わ', 'れ', '報告', 'する', '.']\n",
      "Token IDs: tensor([    9, 26123,     9,    11,     9,   914,     9,   559,     9,    83,\n",
      "            9,  1219,     9,    86,     9,  1231,     9, 25611,     9,    18,\n",
      "            9,   517,  7454,     9,    17,  6979,   493,     9,  4959,     9,\n",
      "           20,     9,    57,     9,   101,     9,    83,     9,  8569,     9,\n",
      "           13,     9,   474,  1411,  5104,     9,  3575,     9,  2479,     2])\n",
      "Masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "\n",
    "    # Reconstruct the sentence--otherwise `tokenizer` will interpret the list\n",
    "    # of string tokens as having already been tokenized by BERT.\n",
    "    sent_str = ' '.join(sent)\n",
    "\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent_str,                  # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = 50,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'][0])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'][0])\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "print('Masks:', attention_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "c8116780-78dc-430d-80ce-fb3a6266eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New labels for all of the input sentences.\n",
    "new_labels = []\n",
    "\n",
    "# The special label ID we'll give to \"extra\" tokens.\n",
    "null_label_id = -100\n",
    "\n",
    "# For each sentence...\n",
    "for (sen, orig_labels) in zip(input_ids, labels):\n",
    "    \n",
    "    # Create a new list to hold the adjusted labels for this sentence.\n",
    "    padded_labels = []\n",
    "\n",
    "    # This will be our index into the original label list.\n",
    "    orig_labels_i = 0 \n",
    "\n",
    "    # For each token in the padded sentence...\n",
    "    for token_id in sen:\n",
    "\n",
    "        # Pull the value out of the tensor.\n",
    "        token_id = token_id.numpy().item()\n",
    "\n",
    "        # If `[PAD]`, `[CLS]`, or `[SEP]`...\n",
    "        if (token_id == tokenizer.pad_token_id) or \\\n",
    "            (token_id == tokenizer.cls_token_id) or \\\n",
    "            (token_id == tokenizer.sep_token_id):\n",
    "            \n",
    "            # Assign it the null label.\n",
    "            padded_labels.append(null_label_id)\n",
    "\n",
    "        # If the token string starts with \"##\"...\n",
    "        elif tokenizer.decode([token_id])[0:2] == '##':\n",
    "\n",
    "            # It's a subword token, and not part of the original dataset, so\n",
    "            # assign it the null label.\n",
    "            padded_labels.append(null_label_id)\n",
    "\n",
    "        # If it's not any of the above...\n",
    "        else:\n",
    "            \n",
    "            # This token corresponds to one of the original ones, so assign it\n",
    "            # it's original label.\n",
    "\n",
    "            # Look up the label for this token.\n",
    "            label_str = orig_labels[orig_labels_i]\n",
    "\n",
    "            # Map the label to its ID, and assign it.\n",
    "            padded_labels.append(label_map[label_str])\n",
    "\n",
    "            # Increment our index into the original labels list.\n",
    "            orig_labels_i += 1\n",
    "\n",
    "    # If we did this right, then the new `padded_labels` list should match\n",
    "    # the length of the tokenized sentence.\n",
    "    assert(len(sen) == len(padded_labels))    \n",
    "\n",
    "    # Store the updated labels list for this sentence.\n",
    "    new_labels.append(padded_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c151f671-b392-4947-8ef5-9f23d0ad5852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence:     ['症例', 'は', '60', '歳', '代', '男性', ',', '当院', '耳鼻咽喉科', 'で', '喉頭', '癌', 'に', '対', 'し', '2', 'ndline', 'として', 'Nivolumab', ' ', '150', 'mg', 'を', '2', '週', '毎', 'に', '投与', '中', 'で', 'あ', 'っ', 'た', '.', '投与', '開始', '4', 'か月', '後', 'の', '採血', 'で', 'T', '－', 'bil', ' ', '0.81', 'mg', '/', 'dl', ',', 'AST', ' ', '91', 'U', '/', 'l', ',', 'ALT', ' ', '144', 'U', '/', 'l', ',', 'ALP', ' ', '1478', 'U', '/', 'l', ' ', 'γGT', ' ', '426', 'U', '/', 'l', 'と', '胆道', '系', '酵素', '優位', 'の', '肝', '障害', 'を', '認め', '消化器', '内科', 'に', '紹介', 'と', 'な', 'っ', 'た', '.', '37.6', '度', 'の', '発熱', 'の', '他', 'に', '自覚症状', 'は', 'な', 'く', ',', '腹部', '所見', 'に', '特記', '事項', 'は', '認め', 'な', 'かった', '.', '血液', '生化学', '検査', 'で', '各種', 'ウイルス', 'マーカー', '・', 'ANA', '・', 'AMA', '2', 'は', '陰性', 'で', 'IgG', '・', 'IgG', '4', 'は', '正常', '範囲', '内', 'で', 'あ', 'っ', 'た', '.', 'CT', 'で', '総', '胆', '管', '・', '左右', '肝', '管', 'の', 'びまん', '性', '拡張', '・', '壁', '肥厚', '及び', '胆嚢', '腫大', '・', '胆嚢', '壁', '肥厚', 'を', '認め', 'た', 'が', ',', ' ', 'MRCP', ',', ' ', 'ERC', 'では', '胆', '管', 'に', '狭窄', 'や', '腫瘍', '性', '病変', 'は', '認め', 'な', 'かった', '.', '肝', '組織', 'では', '肝細胞', 'の', '炎症', '性', '変化', 'や', '壊死', 'は', '目立', 'た', 'ず', ',', '門', '脈', '域', 'に', '多彩', 'な', '炎症', '細胞', 'の', '浸潤', 'と', '一部', 'に', '非', '化膿', '性', '破壊', '性', '胆', '管', '炎', 'の', '像', 'を', '認め', 'た', '.', '以上', 'から', '免疫', 'チェックポイント', '阻害', '剤', '関連', 'の', '胆', '管', '炎', 'を', '疑い', 'Nivolumab', 'の', '投与', 'を', '中止', 'し', 'た', 'が', ',', '生化学', '所見', '・', '画像', '所見', 'に', '改善', 'が', '見', 'ら', 'れ', 'ず', 'PSL', '30', 'mg', 'の', '投与', 'を', '開始', 'し', 'た', '.', '緩徐', 'に', '肝', '胆道', '系', '酵素', 'は', '改善', 'し', 'た', 'が', ',', ' ', 'PSL', '15', 'mg', 'まで', '減量', 'し', 'た', '時点', 'で', '胆', '管', '炎', 'の', '再', '増悪', 'を', '認め', 'た', 'ため', 'UDCA', '600', 'mg', 'を', '追加', 'し', 'た', '.', 'その後', '胆', '管', '炎', 'に', '改善', 'が', '見', 'ら', 'れ', ',', ' ', 'PSL', '終了', 'と', 'し', 'UDCA', '単独', '投与', 'と', 'し', 'た', '.', 'Nivolumab', '投与', 'にて', '奏効', 'が', '得', 'ら', 'れ', 'て', 'い', 'た', 'が', ',', '休', '薬', '後', 'に', '腫瘍', 'は', '再', '増悪', 'したため', ',', '殺', '細胞', '性', '抗がん', '剤', 'による', '全身', '化学療法', 'を', '施行', 'する', 'も', '効果', 'な', 'く', ',', 'その間', 'に', '胆', '管', '炎', 'の', '再燃', 'を', '認め', 'な', 'かった', 'ため', ',', '患者', 'の', '強', 'い', '希望', 'も', 'あ', 'り', '協議', 'の', '結果', 'Nivolumab', '投与', '再開', 'し', 'た', '.', 'その後', '8', 'ヶ月', '以上', '経過', 'する', 'も', '肝機能', 'の', '再燃', 'は', '見', 'ら', 'れ', 'ず', ',', '再び', '腫瘍', 'は', '縮小', 'に', '転じ', 'て', 'い', 'る', '.', '免疫', 'チェックポイント', '阻害', '剤', 'に', '関連', 'し', 'た', '副作用', '(', 'irAE', ')', 'として', '胆', '管', '炎', 'の', '報告', 'は', 'まれ', 'で', 'あ', 'り', ',', '治療', '法', 'について', '現時点', 'での', '一定', 'の', '見解', 'は', 'な', 'い', '.', 'また', '胆', '管', '炎', 'を', '含', 'む', 'irAE', 'から', '回復', '後', 'に', '抗', 'P', '１', '抗体', 'を', '再', '投与', 'すべき', 'か', ',', '恒久的', 'に', '投与', 'を', '中止', 'すべき', 'か', '明らか', 'と', 'な', 'っ', 'て', 'い', 'ない', '.', '今回', 'PSL', 'と', 'UDCA', 'の', '併用', 'で', '胆', '管', '炎', 'の', '改善', 'が', '見', 'ら', 'れ', ',', ' ', 'UDCA', '単独', '投与', '下に', '抗', 'P', '１', '抗体', 'を', '再', '投与', 'し', 'た', '稀', 'な', '一例', 'を', '経験', 'し', 'た', 'ため', '文献', '的', '考察', 'を', '加え', '報告', 'する', '.']\n",
      "\n",
      "Labels:       ['O', 'O', 'B-<timex3>', 'I-<timex3>', 'I-<timex3>', 'O', 'O', 'O', 'O', 'O', 'B-<d>', 'I-<d>', 'O', 'O', 'O', 'B-<r>', 'I-<r>', 'O', 'B-<m-key>', 'O', 'B-<m-val>', 'I-<m-val>', 'O', 'B-<timex3>', 'I-<timex3>', 'I-<timex3>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-<timex3>', 'I-<timex3>', 'I-<timex3>', 'I-<timex3>', 'I-<timex3>', 'O', 'B-<t-test>', 'O', 'B-<t-key>', 'I-<t-key>', 'I-<t-key>', 'O', 'B-<t-val>', 'I-<t-val>', 'I-<t-val>', 'I-<t-val>', 'O', 'B-<t-key>', 'O', 'B-<t-val>', 'I-<t-val>', 'I-<t-val>', 'I-<t-val>', 'O', 'B-<t-key>', 'O', 'B-<t-val>', 'I-<t-val>', 'I-<t-val>', 'I-<t-val>', 'O', 'B-<t-key>', 'O', 'B-<t-val>', 'I-<t-val>', 'I-<t-val>', 'I-<t-val>', 'O', 'B-<t-key>', 'O', 'B-<t-val>', 'I-<t-val>', 'I-<t-val>', 'I-<t-val>', 'O', 'B-<t-key>', 'I-<t-key>', 'I-<t-key>', 'B-<f>', 'O', 'B-<d>', 'I-<d>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-<f>', 'I-<f>', 'O', 'B-<d>', 'O', 'O', 'O', 'B-<d>', 'O', 'O', 'O', 'O', 'B-<d>', 'I-<d>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-<t-test>', 'I-<t-test>', 'I-<t-test>', 'O', 'B-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'I-<d>', 'O', 'O', 'O', 'B-<t-key>', 'I-<t-key>', 'I-<t-key>', 'I-<t-key>', 'O', 'B-<f>', 'I-<f>', 'I-<f>', 'O', 'O', 'O', 'O', 'O', 'B-<t-test>', 'O', 'B-<a>', 'I-<a>', 'I-<a>', 'I-<a>', 'I-<a>', 'I-<a>', 'I-<a>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "BERT Tokens:  ['▁', '症例', '▁', 'は', '▁', '60', '▁', '歳', '▁', '代', '▁', '男性', '▁', ',', '▁当', '院', '▁', '耳', '鼻', '咽', '喉', '科', '▁', 'で', '▁', '喉', '頭', '▁', '癌', '▁', 'に', '▁', '対', '▁', 'し', '▁2', '▁', 'nd', 'line', '▁', 'として', '▁', 'ni', 'vol', 'um', 'ab', '▁', '150', '▁', 'mg', '▁', 'を', '▁2', '▁', '週', '▁', '毎', '▁', 'に', '▁', '投与', '▁', '中', '▁', 'で', '▁', 'あ', '▁', 'っ', '▁', 'た', '▁', '.', '▁', '投与', '▁', '開始', '▁4', '▁', 'か月', '▁', '後', '▁', 'の', '▁', '採', '血', '▁', 'で', '▁t', '▁-', '▁b', 'il', '▁', '0.8', '1', '▁', 'mg', '▁/', '▁', 'dl', '▁', ',', '▁a', 'st', '▁', '91', '▁u', '▁/', '▁l', '▁', ',', '▁', 'alt', '▁14', '4', '▁u', '▁/', '▁l', '▁', ',', '▁al', 'p', '▁14', '78', '▁u', '▁/', '▁l', '▁', 'γ', 'gt', '▁4', '26', '▁u', '▁/', '▁l', '▁', 'と', '▁', '胆', '道', '▁', '系', '▁', '酵素', '▁', '優位', '▁', 'の', '▁', '肝', '▁', '障害', '▁', 'を', '▁', '認め', '▁', '消化', '器', '▁', '内科', '▁', 'に', '▁', '紹介', '▁', 'と', '▁', 'な', '▁', 'っ', '▁', 'た', '▁', '.', '▁3', '7.6', '▁', '度', '▁', 'の', '▁', '発熱', '▁', 'の', '▁他', '▁', 'に', '▁', '自覚', '症状', '▁', 'は', '▁', 'な', '▁', 'く', '▁', ',', '▁', '腹部', '▁', '所', '見', '▁', 'に', '▁', '特記', '▁', '事項', '▁', 'は', '▁', '認め', '▁', 'な', '▁', 'かった', '▁', '.', '▁', '血液', '▁', '生', '化学', '▁', '検査', '▁', 'で', '▁', '各種', '▁', 'ウイルス', '▁', 'マー', 'カー', '▁', '・', '▁', 'ana', '▁', '・', '▁', 'ama', '▁2', '▁', 'は', '▁', '陰', '性', '▁', 'で', '▁i', 'gg', '▁', '・', '▁i', 'gg', '▁4', '▁', 'は', '▁', '正常', '▁', '範囲', '▁', '内', '▁', 'で', '▁', 'あ', '▁', 'っ', '▁', 'た', '▁', '.', '▁', 'ct', '▁', 'で', '▁', '総', '▁', '胆', '▁', '管', '▁', '・', '▁', '左右', '▁', '肝', '▁', '管', '▁', 'の', '▁', 'び', 'まん', '▁', '性', '▁', '拡張', '▁', '・', '▁', '壁', '▁', '肥', '厚', '▁', '及び', '▁', '胆', '嚢', '▁', '腫', '大', '▁', '・', '▁', '胆', '嚢', '▁', '壁', '▁', '肥', '厚', '▁', 'を', '▁', '認め', '▁', 'た', '▁', 'が', '▁', ',', '▁', 'mr', 'cp', '▁', ',', '▁', 'er', 'c', '▁', 'では', '▁', '胆', '▁', '管', '▁', 'に', '▁', '狭', '窄', '▁', 'や', '▁', '腫瘍', '▁', '性', '▁', '病変', '▁', 'は', '▁', '認め', '▁', 'な', '▁', 'かった', '▁', '.', '▁', '肝', '▁', '組織', '▁', 'では', '▁', '肝', '細胞', '▁', 'の', '▁', '炎症', '▁', '性', '▁', '変化', '▁', 'や', '▁', '壊', '死', '▁', 'は', '▁', '目', '立', '▁', 'た', '▁', 'ず', '▁', ',', '▁', '門', '▁', '脈', '▁', '域', '▁', 'に', '▁', '多', '彩', '▁', 'な', '▁', '炎症', '▁', '細胞', '▁', 'の', '▁', '浸', '潤', '▁', 'と', '▁', '一部', '▁', 'に', '▁', '非', '▁', '化', '膿', '▁', '性', '▁', '破壊', '▁', '性', '▁', '胆', '▁', '管', '▁', '炎', '▁', 'の', '▁', '像', '▁', 'を', '▁', '認め', '▁', 'た', '▁', '.', '▁', '以上', '▁', 'から', '▁', '免疫', '▁', 'チェック', 'ポイント', '▁', '阻害', '▁', '剤', '▁', '関連', '▁', 'の', '▁', '胆', '▁', '管', '▁', '炎', '▁', 'を', '▁', '疑い', '▁', 'ni', 'vol', 'um', 'ab', '▁', 'の', '▁', '投与', '▁', 'を', '▁', '中止', '▁', 'し', '▁', 'た', '▁', 'が', '▁', ',', '▁', '生', '化学', '▁', '所', '見', '▁', '・', '▁', '画像', '▁', '所', '見', '▁', 'に', '▁', '改善', '▁', 'が', '▁', '見', '▁', 'ら', '▁', 'れ', '▁', 'ず', '▁p', 'sl', '▁', '30', '▁', 'mg', '▁', 'の', '▁', '投与', '▁', 'を', '▁', '開始', '▁', 'し', '▁', 'た', '▁', '.', '▁', '緩', '徐', '▁', 'に', '▁', '肝', '▁', '胆', '道', '▁', '系', '▁', '酵素', '▁', 'は', '▁', '改善', '▁', 'し', '▁', 'た', '▁', 'が', '▁', ',', '▁p', 'sl', '▁15', '▁', 'mg', '▁', 'まで', '▁', '減', '量', '▁', 'し', '▁', 'た', '▁', '時点', '▁', 'で', '▁', '胆', '▁', '管', '▁', '炎', '▁', 'の', '▁', '再', '▁', '増', '悪', '▁', 'を', '▁', '認め', '▁', 'た', '▁', 'ため', '▁', 'ud', 'ca', '▁', '600', '▁', 'mg', '▁', 'を', '▁', '追加', '▁', 'し', '▁', 'た', '▁', '.', '▁その後', '▁', '胆', '▁', '管', '▁', '炎', '▁', 'に', '▁', '改善', '▁', 'が', '▁', '見', '▁', 'ら', '▁', 'れ', '▁', ',', '▁p', 'sl', '▁', '終了', '▁', 'と', '▁', 'し', '▁', 'ud', 'ca', '▁', '単独', '▁', '投与', '▁', 'と', '▁', 'し', '▁', 'た', '▁', '.', '▁', 'ni', 'vol', 'um', 'ab', '▁', '投与', '▁', 'にて', '▁', '奏', '効', '▁', 'が', '▁', '得', '▁', 'ら', '▁', 'れ', '▁', 'て', '▁', 'い', '▁', 'た', '▁', 'が', '▁', ',', '▁', '休', '▁', '薬', '▁', '後', '▁', 'に', '▁', '腫瘍', '▁', 'は', '▁', '再', '▁', '増', '悪', '▁', 'したため', '▁', ',', '▁', '殺', '▁', '細胞', '▁', '性', '▁', '抗', 'がん', '▁', '剤', '▁', 'による', '▁', '全身', '▁', '化学', '療法', '▁', 'を', '▁', '施行', '▁', 'する', '▁', 'も', '▁', '効果', '▁', 'な', '▁', 'く', '▁', ',', '▁その間', '▁', 'に', '▁', '胆', '▁', '管', '▁', '炎', '▁', 'の', '▁', '再', '燃', '▁', 'を', '▁', '認め', '▁', 'な', '▁', 'かった', '▁', 'ため', '▁', ',', '▁', '患者', '▁', 'の', '▁', '強', '▁', 'い', '▁', '希望', '▁', 'も', '▁', 'あ', '▁', 'り', '▁', '協議', '▁', 'の', '▁', '結果', '▁', 'ni', 'vol', 'um', 'ab', '▁', '投与', '▁', '再開', '▁', 'し', '▁', 'た', '▁', '.', '▁その後', '▁8', '▁', 'ヶ月', '▁', '以上', '▁', '経過', '▁', 'する', '▁', 'も', '▁', '肝', '機能', '▁', 'の', '▁', '再', '燃', '▁', 'は', '▁', '見', '▁', 'ら', '▁', 'れ', '▁', 'ず', '▁', ',', '▁', '再び', '▁', '腫瘍', '▁', 'は', '▁', '縮小', '▁', 'に', '▁', '転', 'じ', '▁', 'て', '▁', 'い', '▁', 'る', '▁', '.', '▁', '免疫', '▁', 'チェック', 'ポイント', '▁', '阻害', '▁', '剤', '▁', 'に', '▁', '関連', '▁', 'し', '▁', 'た', '▁', '副作用', '▁(', '▁', 'ira', 'e', '▁', ')', '▁', 'として', '▁', '胆', '▁', '管', '▁', '炎', '▁', 'の', '▁', '報告', '▁', 'は', '▁', 'まれ', '▁', 'で', '▁', 'あ', '▁', 'り', '▁', ',', '▁', '治療', '▁', '法', '▁', 'について', '▁', '現', '時点', '▁', 'での', '▁', '一定', '▁', 'の', '▁', '見解', '▁', 'は', '▁', 'な', '▁', 'い', '▁', '.', '▁また', '▁', '胆', '▁', '管', '▁', '炎', '▁', 'を', '▁', '含', '▁', 'む', '▁', 'ira', 'e', '▁', 'から', '▁', '回復', '▁', '後', '▁', 'に', '▁', '抗', '▁p', '▁', '1', '▁', '抗体', '▁', 'を', '▁', '再', '▁', '投与', '▁', 'すべき', '▁', 'か', '▁', ',', '▁', '恒', '久', '的', '▁', 'に', '▁', '投与', '▁', 'を', '▁', '中止', '▁', 'すべき', '▁', 'か', '▁', '明らか', '▁', 'と', '▁', 'な', '▁', 'っ', '▁', 'て', '▁', 'い', '▁', 'ない', '▁', '.', '▁', '今回', '▁p', 'sl', '▁', 'と', '▁', 'ud', 'ca', '▁', 'の', '▁', '併用', '▁', 'で', '▁', '胆', '▁', '管', '▁', '炎', '▁', 'の', '▁', '改善', '▁', 'が', '▁', '見', '▁', 'ら', '▁', 'れ', '▁', ',', '▁', 'ud', 'ca', '▁', '単独', '▁', '投与', '▁', '下に', '▁', '抗', '▁p', '▁', '1', '▁', '抗体', '▁', 'を', '▁', '再', '▁', '投与', '▁', 'し', '▁', 'た', '▁', '稀', '▁', 'な', '▁', '一例', '▁', 'を', '▁', '経験', '▁', 'し', '▁', 'た', '▁', 'ため', '▁', '文献', '▁', '的', '▁', '考察', '▁', 'を', '▁', '加', 'え', '▁', '報告', '▁', 'する', '▁', '.']\n",
      "\n",
      "Token IDs:    tensor([    9, 26123,     9,    11,     9,   630,     9,   559,     9,   261,\n",
      "            9,  1219,     9,    83,  6979,   493,     9,  3475,  5024, 29875,\n",
      "        16950,   482,     9,    19,     9, 16950,   402,     9,  5425,     9,\n",
      "           17,     9,   618,     9,    32,   892,     9,  4224,  9322,     9,\n",
      "           34,     9,  3570,  9551,  3298,  3947,     9,  2846,     9,     2])\n",
      "\n",
      "New Labels:   [10, 10, 13, 6, 6, 10, 10, 10, 10, 10, 4, 25, 10, 10, 10, 22, 12, 10, 3, 10, 2, 7, 10, 13, 6, 6, 10, 10, 10, 10, 10, 10, 10, 10, 13, 6, 6, 6, 6, 10, 0, 10, 5, 23, 23, 10, 26, 20, 20, 20]\n",
      "\n",
      "Mask:         tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1])\n"
     ]
    }
   ],
   "source": [
    "print('\\nSentence:    ', sentences[2])\n",
    "print('\\nLabels:      ', labels[2])\n",
    "print('\\nBERT Tokens: ', tokenizer.tokenize(' '.join(sentences[2])))\n",
    "print('\\nToken IDs:   ', input_ids[2])\n",
    "print('\\nNew Labels:  ', new_labels[2])\n",
    "print('\\nMask:        ', attention_masks[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a6dec4f5-0f71-4c6c-8f46-5e5282296237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists into PyTorch tensors.\n",
    "\n",
    "# `input_ids` is a list of tensor arrays--stack them into a matrix with size\n",
    "# [7,660  x  50].\n",
    "pt_input_ids = torch.stack(input_ids, dim=0)\n",
    "\n",
    "# `attention_masks` is a list of tensor arrays--stack them into a matrix with\n",
    "# size [7,660  x  50].\n",
    "pt_attention_masks = torch.stack(attention_masks, dim=0)\n",
    "\n",
    "# Labels is a list of lists. Convert it into a tensor matrix with size \n",
    "# [7,660  x  50].\n",
    "pt_labels = torch.tensor(new_labels, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1c828f19-9aee-40d6-84f4-46aeff48b6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  118 training samples\n",
      "    0 val samples\n",
      "   30 test samples\n",
      "118\n",
      "30\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(pt_input_ids, pt_attention_masks, pt_labels)\n",
    "\n",
    "# Create a 80-20 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "val_size = 0\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "test_dataset, val_dataset = random_split(test_dataset, [test_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} val samples'.format(val_size))\n",
    "print('{:>5,} test samples'.format(test_size))\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(val_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e921d45c-ecb1-4ce0-b7a7-52361bd2d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "21040db6-4519-4181-b975-e4e65ddde19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the number of labels in our dataset, so we will be doing 18-way classification (all labels plus our padding label)\n",
    "len(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "107daf17-8d79-46cc-92b0-a3c544c2c7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at rinna/japanese-roberta-base were not used when initializing RobertaForTokenClassification: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at rinna/japanese-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, RobertaForTokenClassification, AdamW, RobertaConfig\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-roberta-base\")\n",
    "tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading\n",
    "\n",
    "model = RobertaForTokenClassification.from_pretrained(\"rinna/japanese-roberta-base\",\n",
    "    num_labels = 27, # The number of output labels--18 for our NER dataset\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# from transformers import BertForTokenClassification, AdamW, BertConfig\n",
    "\n",
    "# # Load BertForTokenClassification \n",
    "# model = BertForTokenClassification.from_pretrained(\n",
    "#     \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "#     num_labels = len(label_map) + 1, # The number of output labels--18 for our NER dataset\n",
    "#     output_attentions = False, # Whether the model returns attentions weights.\n",
    "#     output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "# )\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()\n",
    "# Load the AdamW optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-5, # args.learning_rate \n",
    "                  eps = 1e-8 # args.adam_epsilon \n",
    "                )\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs \n",
    "epochs = 100\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3dafc99c-a0eb-4c24-af33-5780cdcfac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b8f0ed05-903f-415f-a26d-31cbfa68b219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 2.35\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.91\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.84\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.80\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 5 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.80\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 6 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.75\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 7 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.72\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 8 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.74\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 9 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.73\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 10 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.70\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 11 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.68\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 12 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.66\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 13 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.67\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 14 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.67\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 15 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.62\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 16 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.59\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 17 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.58\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 18 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.55\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 19 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.56\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 20 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.55\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 21 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.53\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 22 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.54\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 23 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.52\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 24 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.50\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 25 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.49\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 26 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.46\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 27 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.46\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 28 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.45\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 29 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.44\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 30 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.41\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 31 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.41\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 32 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.41\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 33 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.37\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 34 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.33\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 35 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.32\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 36 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.33\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 37 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.30\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 38 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.27\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 39 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.25\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 40 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.27\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 41 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 42 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.23\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 43 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.18\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 44 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.18\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 45 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.16\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 46 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.14\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 47 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 48 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.12\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 49 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.11\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 50 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.09\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 51 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 52 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 53 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.08\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 54 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 55 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 56 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 57 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 58 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 59 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.98\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 60 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.96\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 61 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.95\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 62 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.95\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 63 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.96\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 64 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.93\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 65 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.93\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 66 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.92\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 67 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.92\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 68 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.91\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 69 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.90\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 70 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.89\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 71 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.88\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 72 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.88\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 73 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.88\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 74 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.87\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 75 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.85\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 76 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.84\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 77 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.85\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 78 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.86\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 79 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.83\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 80 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.83\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 81 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.83\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 82 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.81\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 83 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.83\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 84 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.82\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 85 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.82\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 86 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.81\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 87 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.81\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 88 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.78\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 89 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.81\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 90 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.80\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 91 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.77\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 92 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.79\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 93 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.79\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 94 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.77\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 95 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.78\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 96 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.78\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 97 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.78\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 98 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.78\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 99 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.75\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "======== Epoch 100 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.77\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertfortokenclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.TokenClassifierOutput\n",
    "        result = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        loss = result.loss\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "78b7bb49-8eeb-4af9-adcb-997269d33d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "36792859-498b-4c42-b22d-f6bfcb1cbd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 148 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 16  \n",
    "\n",
    "# Create the DataLoader.\n",
    "# prediction_data = TensorDataset(pt_input_ids, pt_attention_masks, pt_labels)\n",
    "prediction_sampler = SequentialSampler(test_dataset)\n",
    "prediction_dataloader = DataLoader(test_dataset, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(pt_input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions, true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      result = model(b_input_ids, \n",
    "                      token_type_ids=None, \n",
    "                      attention_mask=b_input_mask,\n",
    "                      return_dict=True)\n",
    "\n",
    "  logits = result.logits\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "66e9894e-ec6c-4d84-905a-17f905e07cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After flattening the batches, the predictions have shape:\n",
      "     (30, 50, 27)\n",
      "\n",
      "After choosing the highest scoring label for each token:\n",
      "     (30, 50)\n",
      "\n",
      "After flattening the sentences, we have predictions:\n",
      "     (1500,)\n",
      "and ground truth:\n",
      "     (1500,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# First, combine the results across the batches.\n",
    "all_predictions = np.concatenate(predictions, axis=0)\n",
    "all_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "print(\"After flattening the batches, the predictions have shape:\")\n",
    "print(\"    \", all_predictions.shape)\n",
    "\n",
    "# Next, let's remove the third dimension (axis 2), which has the scores\n",
    "# for all 18 labels. \n",
    "\n",
    "# For each token, pick the label with the highest score.\n",
    "predicted_label_ids = np.argmax(all_predictions, axis=2)\n",
    "\n",
    "print(\"\\nAfter choosing the highest scoring label for each token:\")\n",
    "print(\"    \", predicted_label_ids.shape) \n",
    "\n",
    "# Finally, for the sake of scoring, we don't actually care about the different\n",
    "# sentences--we just look at whether the model made correct predictions for the\n",
    "# individual tokens.\n",
    "\n",
    "# Eliminate axis 0, which corresponds to the sentences.\n",
    "predicted_label_ids = np.concatenate(predicted_label_ids, axis=0)\n",
    "all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
    "\n",
    "print(\"\\nAfter flattening the sentences, we have predictions:\")\n",
    "print(\"    \", predicted_label_ids.shape)\n",
    "print(\"and ground truth:\")\n",
    "print(\"    \", all_true_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "68138468-65c8-4393-8d53-35ac31060a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering out `null` tokens, length = 1,500\n",
      " After filtering out `null` tokens, length = 1,500\n",
      "[10, 10, 6, 6, 10, 10, 10, 13, 13, 6, 10, 10, 4, 4, 25, 25, 25, 25, 25, 25, 25, 25, 25, 6, 6, 6, 10, 10, 10, 10, 10, 6, 6, 10, 10, 10, 10, 10, 6, 6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 10, 10, 10, 25, 25, 25, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 18, 18, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 10, 10, 13, 13, 6, 4, 4, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 4, 10, 10, 10, 10, 10, 6, 6, 6, 6, 10, 10, 24, 24, 24, 24, 24, 24, 24, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25, 10, 10, 10, 10, 10, 6, 25, 10, 10, 10, 4, 4, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 25, 4, 4, 4, 4, 25, 25, 10, 10, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 10, 10, 10, 13, 6, 10, 10, 10, 10, 4, 25, 25, 25, 25, 10, 10, 4, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 4, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25, 10, 10, 4, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25, 4, 4, 10, 10, 10, 10, 10, 10, 4, 10, 25, 25, 25, 25, 25, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 10, 10, 10, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 18, 18, 18, 18, 18, 10, 10, 10, 10, 15, 10, 10, 10, 10, 25, 25, 25, 10, 4, 4, 25, 25, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 10, 10, 10, 10, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 4, 18, 18, 18, 18, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25, 25, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 13, 13, 13, 13, 13, 13, 6, 10, 4, 25, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 4, 4, 25, 25, 25, 25, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 18, 18, 18, 18, 10, 10, 10, 10, 10, 18, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 19, 19, 19, 19, 19, 19, 10, 19, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 10, 10, 10, 10, 10, 25, 25, 25, 25, 10, 10, 10, 10, 6, 6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 10, 10, 10, 10, 4, 25, 25, 25, 25, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 10, 10, 10, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 10, 6, 6, 6, 6, 6, 6, 6, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 14, 14, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 10, 10, 10, 10, 10, 10, 10, 6, 6, 10, 10, 10, 10, 10, 25, 25, 25, 25, 4, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 4, 25, 4, 10, 10, 10, 10, 10, 10, 18, 21, 18, 18, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 4, 4, 4, 4, 4, 4, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 4, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 10, 10, 10, 25, 25, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 18, 18, 18, 18, 10, 10, 6, 6, 6, 10, 10, 6, 6, 10, 10, 10, 13, 4, 25, 25, 4, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 10, 10, 6, 6, 6, 10, 25, 25, 25, 25, 25, 25, 25, 25, 10, 10, 10, 10, 10, 25, 25, 25, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 10, 10, 10, 10, 25, 25, 10, 10, 10, 10, 6, 6, 10, 10, 10, 10, 6, 6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 10, 10, 6, 6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "# Construct new lists of predictions which don't include any null tokens.\n",
    "real_token_predictions = []\n",
    "real_token_labels = []\n",
    "\n",
    "# For each of the input tokens in the dataset...\n",
    "for i in range(len(all_true_labels)):\n",
    "\n",
    "    # If it's not a token with a null label...\n",
    "    if not all_true_labels[i] == -100:\n",
    "        \n",
    "        # Add the prediction and the ground truth to their lists.\n",
    "        real_token_predictions.append(predicted_label_ids[i])\n",
    "        real_token_labels.append(all_true_labels[i])\n",
    "\n",
    "print(\"Before filtering out `null` tokens, length = {:,}\".format(len(all_true_labels)))\n",
    "print(\" After filtering out `null` tokens, length = {:,}\".format(len(real_token_labels)))\n",
    "print(real_token_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f0415008-f44e-4879-9e37-ed0cc5a7293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 56.27%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate the F1 score. Because this is a multi-class problem, we have\n",
    "# to set the `average` parameter. TODO - What does `micro` do?\n",
    "f1 = f1_score(real_token_labels, real_token_predictions, average='micro') \n",
    "\n",
    "print (\"F1 score: {:.2%}\".format(f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da5fdcc-c52c-4c59-a8e1-ea98aa4e7e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
